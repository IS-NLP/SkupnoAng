{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copied from preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Domen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Domen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Domen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.883048\n",
       "1    0.116952\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "train_data_path = \"./data/English dataset/train.jsonl\"\n",
    "test_data_path = \"./data/English dataset/test.jsonl\"\n",
    "\n",
    "def preprocess_text(text): # From the labs\n",
    "\t# Tokenize the text into words\n",
    "\twords = word_tokenize(text.lower())  # Convert text to lowercase\n",
    "\n",
    "\t# Remove punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\twords = [word.translate(table) for word in words if word.isalpha()]\n",
    "\n",
    "\t# Remove stopwords\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\twords = [word for word in words if word not in stop_words]\n",
    "\n",
    "\t# Lemmatization\n",
    "\tlemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "\t# Join the words back into a string\n",
    "\tpreprocessed_text = ' '.join(lemmatized_words)\n",
    "\treturn preprocessed_text\n",
    "\n",
    "train_data = pd.DataFrame(datasets.load_dataset(\"json\", data_files=train_data_path)[\"train\"])\n",
    "test_dataset = pd.DataFrame(datasets.load_dataset(\"json\", data_files=test_data_path)[\"train\"])\n",
    "\n",
    "label_map = {\"Contradiction\": 1, \"Entailment\": 0, \"NotMentioned\": 0}\n",
    "train_data[\"label\"] = train_data[\"label\"].map(label_map)\n",
    "test_dataset[\"label\"] = test_dataset[\"label\"].map(label_map)\n",
    "\n",
    "train_data = train_data.drop(\"doc_id\", axis=1)\n",
    "train_data = train_data.drop(\"key\", axis=1)\n",
    "test_dataset = test_dataset.drop(\"doc_id\", axis=1)\n",
    "test_dataset = test_dataset.drop(\"key\", axis=1)\n",
    "\n",
    "train_data[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    train_data = pd.DataFrame(datasets.load_dataset(\"json\", data_files=train_data_path)[\"train\"])\n",
    "    test_dataset = pd.DataFrame(datasets.load_dataset(\"json\", data_files=test_data_path)[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_splitter(p, text_lim, overlap=250, allowed_delimiters=\" ,.?!\"):\n",
    "    i = text_lim\n",
    "    while not p[i] in allowed_delimiters and i > 0:\n",
    "        i -= 1\n",
    "    p1 = p[:i]\n",
    "\n",
    "    d = len(p) - i\n",
    "    if d < text_lim-overlap:\n",
    "        j = text_lim-overlap\n",
    "        while not p[j] in allowed_delimiters and j > 0:\n",
    "            j += 1\n",
    "        p2 = p[j:]\n",
    "        return [p1,p2]\n",
    "    else:\n",
    "        return p1 + text_splitter(p[(i-overlap):], text_lim, overlap)\n",
    "\n",
    "def dataset_splitter(df, token_lim = 768, overlap=50, allowed_delimiters=\" ,.?!\"): # ensures the premises are roughly within the token limit\n",
    "    text_lim = int(token_lim * 3.5)\n",
    "    overlap = int(overlap*3.5)\n",
    "    to_app = []\n",
    "    for i,r in df.iterrows():\n",
    "        if len(r['premise']) > text_lim:\n",
    "            seg = text_splitter(r['premise'], text_lim, overlap=overlap, allowed_delimiters=allowed_delimiters)\n",
    "\n",
    "            for s in seg:\n",
    "                nr = {'premise': s, 'hypothesis': r['hypothesis'], 'label': r['label']}\n",
    "                to_app.append(nr)\n",
    "            \n",
    "            df.drop(i)\n",
    "    \n",
    "    df.append(pd.DataFrame(to_app))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2091\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ds = Dataset.from_pandas(train_data)\n",
    "ds = ds.select_columns([\"hypothesis\", \"premise\", \"label\"])\n",
    "ds = ds.select_columns([\"hypothesis\", \"premise\", \"label\"])\n",
    "\n",
    "dss = ds.train_test_split(0.2, seed=42)\n",
    "train_dataset = dss['train']\n",
    "valid_dataset = dss['test']\n",
    "test_dataset = Dataset.from_pandas(test_dataset)\n",
    "\n",
    "test_corpus = test_dataset['premise']\n",
    "test_hypothesis = test_dataset['hypothesis']\n",
    "print(len(test_hypothesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 7191\n"
     ]
    }
   ],
   "source": [
    "print(len(set(ds['hypothesis'])), len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 2091\n"
     ]
    }
   ],
   "source": [
    "print(len(set(test_dataset['hypothesis'])), len(test_dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom evaluator\n",
    "from sentence_transformers.evaluation import SentenceEvaluator\n",
    "from collections import defaultdict\n",
    "from sentence_transformers.util import cos_sim\n",
    "import torch\n",
    "\n",
    "class MyRecallEval(SentenceEvaluator):\n",
    "    def structure(test_dataset):\n",
    "        corpus = dict(zip(test_dataset['premise'], test_dataset['premise']))\n",
    "        queries = dict(zip(test_dataset['hypothesis'], test_dataset['hypothesis']))\n",
    "        relevant_docs = defaultdict(list)\n",
    "\n",
    "        for k in range(len(test_dataset)):\n",
    "            if test_dataset['label'][k] > 0:\n",
    "                relevant_docs[test_dataset['hypothesis'][k]].append(test_dataset['premise'][k])\n",
    "\n",
    "        return (queries, corpus, relevant_docs)\n",
    "        \n",
    "    def __init__(self, data, recall_ks=(5, 10, 20, 50), cluster_k=50,cluster_min_hits=10,name: str = \"\"):\n",
    "        super().__init__()\n",
    "        hypotheses, premises, relevant_premises = MyRecallEval.structure(data)\n",
    "        self.hypotheses = hypotheses\n",
    "        self.premises = premises\n",
    "        self.relevant_premises = relevant_premises\n",
    "        self.recall_ks = recall_ks\n",
    "        self.cluster_k = cluster_k\n",
    "        self.cluster_min_hits = cluster_min_hits\n",
    "        self.name = name\n",
    "\n",
    "        self.greater_is_better = True\n",
    "        self.primary_metric = f\"recall@{max(recall_ks)}\"\n",
    "\n",
    "        # Fixed ordering (important!)\n",
    "        self.hyp_ids = list(hypotheses.keys())\n",
    "        self.premise_ids = list(premises.keys())\n",
    "\n",
    "    def __call__(self, model, output_path=None, epoch=-1, steps=-1):\n",
    "        # 1. Encode\n",
    "        hyp_texts = [self.hypotheses[h] for h in self.hyp_ids]\n",
    "        prem_texts = [self.premises[p] for p in self.premise_ids]\n",
    "\n",
    "        hyp_emb = model.encode(hyp_texts, convert_to_tensor=True, normalize_embeddings=True)\n",
    "        prem_emb = model.encode(prem_texts, convert_to_tensor=True, normalize_embeddings=True)\n",
    "\n",
    "        # 2. Similarity matrix\n",
    "        # TODO should we use cos_sim?\n",
    "        scores = cos_sim(hyp_emb, prem_emb)  # shape: [num_hyp, num_prem]\n",
    "\n",
    "        recalls = {k: [] for k in self.recall_ks}\n",
    "        normrecalls = {k: [] for k in self.recall_ks}\n",
    "\n",
    "        cluster_success = []\n",
    "\n",
    "        # 3. Per-hypothesis evaluation\n",
    "        for i, hyp_id in enumerate(self.hyp_ids):\n",
    "            relevant = self.relevant_premises[hyp_id]\n",
    "            if not relevant:\n",
    "                continue\n",
    "\n",
    "            relevant_idx = {self.premise_ids.index(pid) for pid in relevant}\n",
    "\n",
    "            ranked = torch.argsort(scores[i], descending=True)\n",
    "\n",
    "            for k in self.recall_ks:\n",
    "                topk = ranked[:k].tolist()\n",
    "                hits = len(set(topk) & relevant_idx)\n",
    "                normrecalls[k].append(hits / min(k,len(relevant_idx)))\n",
    "                recalls[k].append(hits / len(relevant_idx))\n",
    "\n",
    "            # Cluster recall\n",
    "            top_cluster = ranked[: self.cluster_k].tolist()\n",
    "            hits = len(set(top_cluster) & relevant_idx)\n",
    "            cluster_success.append(hits >= self.cluster_min_hits)\n",
    "\n",
    "        # 4. Aggregate metrics\n",
    "        metrics = {\n",
    "            f\"recall@{k}\": float(np.mean(recalls[k])) for k in self.recall_ks\n",
    "        }\n",
    "        for k in self.recall_ks:\n",
    "            metrics[f\"normalized_recall@{k}\"] = float(np.mean(normrecalls[k]))\n",
    "        metrics[\"cluster_recall\"] = float(np.mean(cluster_success))\n",
    "\n",
    "        # Optional: store in model card\n",
    "        self.store_metrics_in_model_card_data(model, metrics, epoch, steps)\n",
    "\n",
    "        return self.prefix_name_to_metrics(metrics, self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_ret_eval(test_dataset):\n",
    "    corpus = dict(zip(test_dataset['premise'], test_dataset['premise']))\n",
    "    queries = dict(zip(test_dataset['hypothesis'], test_dataset['hypothesis']))\n",
    "    relevant_docs = defaultdict(list)\n",
    "\n",
    "    for k in range(len(test_dataset)):\n",
    "        if test_dataset['label'][k] > 0:\n",
    "            relevant_docs[test_dataset['hypothesis'][k]].append(test_dataset['premise'][k])\n",
    "    \n",
    "\n",
    "    inf_ret_ev = InformationRetrievalEvaluator(\n",
    "        queries= queries,\n",
    "        corpus = corpus,\n",
    "        relevant_docs = relevant_docs,\n",
    "        #similarity_fn_names= [\"cosine\"],\n",
    "        show_progress_bar=True,\n",
    "        batch_size= 16,\n",
    "        #main_score_function=\"Recall@10\"\n",
    "    )\n",
    "\n",
    "    return inf_ret_ev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "def get_bin_eval(test_dataset):\n",
    "    \"\"\"\n",
    "        BinnaryClassification returns: F1, Percision, Recall, Avg Percision, Matthews Correlation, \n",
    "    \"\"\"\n",
    "    bin_acc_ev = BinaryClassificationEvaluator(\n",
    "        sentences1= test_dataset['hypothesis'],\n",
    "        sentences2= test_dataset['premise'],\n",
    "        labels= test_dataset['label'],\n",
    "        similarity_fn_names= [\"cosine\", \"dot\"],\n",
    "        show_progress_bar= True,\n",
    "        batch_size= 16\n",
    "    )\n",
    "    return bin_acc_ev"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model\n",
    "- Straight from the box, unmodified\n",
    "-  [msmarco-MiniLM-L6-cos-v5](https://huggingface.co/sentence-transformers/msmarco-MiniLM-L6-cos-v5) Trained specificly for query-passage retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = \"models\\jina-embeddings-v2-small-en\" \n",
    "base_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " float16 should speed up the model, while having minimal impact on preformance: [documentation](https://www.sbert.net/docs/sentence_transformer/usage/efficiency.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the base model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n I | I i\\nI I| L\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    " I | I i\n",
    "I I| L\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer\n",
    "\n",
    "fine_model = base_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup of Trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "k = 10\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"models/tuned_model\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=3e-5,\n",
    "    seed=42,\n",
    "    metric_for_best_model=f\"eval_cosine_recall@10\",\n",
    "    #greater_is_better=False,\n",
    "  \tload_best_model_at_end=True,\n",
    "  \tweight_decay=0.01,\n",
    "    \n",
    "    #warmup_ratio=0.1,\n",
    "    #fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    #bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "    #batch_sampler=BatchSamplers.NO_DUPLICATES,  # losses that use \"in-batch negatives\" benefit from no duplicates\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50, # how often we eval\n",
    "    #save_strategy=\"best\",\n",
    "    torch_empty_cache_steps = None,\n",
    "    save_steps=50,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    run_name=\"mpnet-base-all-nli-triplet\",  # Will be used in W&B if `wandb` is installed\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contrastive loss** Used for binary labled pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import ContrastiveLoss, MultipleNegativesRankingLoss\n",
    "\n",
    "def trainer_cl(m, train_dataset, valid_dataset, args): # bad trainer, assumes a hypothesis has only one correct answer\n",
    "    td = {''}\n",
    "    loss = ContrastiveLoss(m)\n",
    "\n",
    "    evaluator = get_ret_eval(valid_dataset)\n",
    "\n",
    "    trainer = SentenceTransformerTrainer(\n",
    "        model = m,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        loss=loss,\n",
    "        evaluator=evaluator,\n",
    "        args=args\n",
    "    )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "\n",
    "def trainer_mnr(m, train_dataset, valid_dataset, args):\n",
    "    td = {''}\n",
    "    loss = MultipleNegativesRankingLoss(m)\n",
    "\n",
    "    evaluator = get_ret_eval(valid_dataset)\n",
    "\n",
    "    trainer = SentenceTransformerTrainer(\n",
    "        model = m,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        loss=loss,\n",
    "        evaluator=evaluator,\n",
    "        args=args\n",
    "    )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this if using a trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "print(set(test_dataset['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [131/131 05:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbfeaab4b6c4bb59382d89bc6192570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa530d8978e46bbaccde4889360d685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:45<00:00, 45.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss 4.124613285064697\n",
      "eval_model_preparation_time 0.001\n",
      "eval_cosine_accuracy@1 0.1111111111111111\n",
      "eval_cosine_accuracy@3 0.2222222222222222\n",
      "eval_cosine_accuracy@5 0.4444444444444444\n",
      "eval_cosine_accuracy@10 0.4444444444444444\n",
      "eval_cosine_precision@1 0.1111111111111111\n",
      "eval_cosine_precision@3 0.14814814814814814\n",
      "eval_cosine_precision@5 0.17777777777777776\n",
      "eval_cosine_precision@10 0.15555555555555556\n",
      "eval_cosine_recall@1 0.0031746031746031746\n",
      "eval_cosine_recall@3 0.021869488536155203\n",
      "eval_cosine_recall@5 0.06739248405915071\n",
      "eval_cosine_recall@10 0.09457332790666123\n",
      "eval_cosine_ndcg@10 0.1673362937459519\n",
      "eval_cosine_mrr@10 0.2222222222222222\n",
      "eval_cosine_map@100 0.10373468805936607\n",
      "eval_runtime 350.3169\n",
      "eval_samples_per_second 5.969\n",
      "eval_steps_per_second 0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = trainer_mnr(base_model, train_dataset, valid_dataset, args)\n",
    "ev = get_ret_eval(test_dataset)\n",
    "test_dataset = test_dataset.select_columns([\"hypothesis\", \"premise\", \"label\"])\n",
    "\n",
    "ret = trainer.evaluate(eval_dataset=test_dataset)\n",
    "for k, v in ret.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.124613285064697, 'eval_model_preparation_time': 0.001, 'eval_cosine_accuracy@1': 0.1111111111111111, 'eval_cosine_accuracy@3': 0.2222222222222222, 'eval_cosine_accuracy@5': 0.4444444444444444, 'eval_cosine_accuracy@10': 0.4444444444444444, 'eval_cosine_precision@1': 0.1111111111111111, 'eval_cosine_precision@3': 0.14814814814814814, 'eval_cosine_precision@5': 0.17777777777777776, 'eval_cosine_precision@10': 0.15555555555555556, 'eval_cosine_recall@1': 0.0031746031746031746, 'eval_cosine_recall@3': 0.021869488536155203, 'eval_cosine_recall@5': 0.06739248405915071, 'eval_cosine_recall@10': 0.09457332790666123, 'eval_cosine_ndcg@10': 0.1673362937459519, 'eval_cosine_mrr@10': 0.2222222222222222, 'eval_cosine_map@100': 0.10373468805936607, 'eval_runtime': 350.3169, 'eval_samples_per_second': 5.969, 'eval_steps_per_second': 0.374}\n"
     ]
    }
   ],
   "source": [
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1439\n"
     ]
    }
   ],
   "source": [
    "print(len((valid_dataset['hypothesis'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [360/360 21:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cosine Accuracy@1</th>\n",
       "      <th>Cosine Accuracy@3</th>\n",
       "      <th>Cosine Accuracy@5</th>\n",
       "      <th>Cosine Accuracy@10</th>\n",
       "      <th>Cosine Precision@1</th>\n",
       "      <th>Cosine Precision@3</th>\n",
       "      <th>Cosine Precision@5</th>\n",
       "      <th>Cosine Precision@10</th>\n",
       "      <th>Cosine Recall@1</th>\n",
       "      <th>Cosine Recall@3</th>\n",
       "      <th>Cosine Recall@5</th>\n",
       "      <th>Cosine Recall@10</th>\n",
       "      <th>Cosine Ndcg@10</th>\n",
       "      <th>Cosine Mrr@10</th>\n",
       "      <th>Cosine Map@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.555478</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>0.028280</td>\n",
       "      <td>0.053482</td>\n",
       "      <td>0.171464</td>\n",
       "      <td>0.265873</td>\n",
       "      <td>0.109325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.677200</td>\n",
       "      <td>2.279555</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.009427</td>\n",
       "      <td>0.036510</td>\n",
       "      <td>0.057342</td>\n",
       "      <td>0.086818</td>\n",
       "      <td>0.280941</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.170619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.677200</td>\n",
       "      <td>2.203582</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.009427</td>\n",
       "      <td>0.036510</td>\n",
       "      <td>0.061457</td>\n",
       "      <td>0.087758</td>\n",
       "      <td>0.283055</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.194654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.259500</td>\n",
       "      <td>2.162162</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.009427</td>\n",
       "      <td>0.034373</td>\n",
       "      <td>0.045937</td>\n",
       "      <td>0.105160</td>\n",
       "      <td>0.259081</td>\n",
       "      <td>0.382716</td>\n",
       "      <td>0.182064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.259500</td>\n",
       "      <td>2.047812</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.009427</td>\n",
       "      <td>0.040625</td>\n",
       "      <td>0.159185</td>\n",
       "      <td>0.177097</td>\n",
       "      <td>0.293770</td>\n",
       "      <td>0.398148</td>\n",
       "      <td>0.209145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.122500</td>\n",
       "      <td>2.012819</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.009427</td>\n",
       "      <td>0.036510</td>\n",
       "      <td>0.159185</td>\n",
       "      <td>0.174960</td>\n",
       "      <td>0.286270</td>\n",
       "      <td>0.411111</td>\n",
       "      <td>0.209028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.122500</td>\n",
       "      <td>2.009597</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.009427</td>\n",
       "      <td>0.040625</td>\n",
       "      <td>0.159185</td>\n",
       "      <td>0.174960</td>\n",
       "      <td>0.287672</td>\n",
       "      <td>0.411111</td>\n",
       "      <td>0.208326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b6a6868da44b4c885e21527ad15c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff71becaf6d41ccb0b00955f56be181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:06<00:00,  6.65s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370e22d261f74281bac9856cd3f0e78d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4908ce0262ea4ad090610bcfbc1e10ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:06<00:00,  6.61s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d228eaf4d14bcc8eeb1b87be0f6e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12eca24e46ed4fdfbea6ff6df0bb72ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:09<00:00,  9.85s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33b5de0e2ff4ca4915262727d9c5356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3702b99aef54357a9c16c4ed087ccb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:10<00:00, 10.93s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0986251b548648a39d1cfb661303c523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8baee3819ca4727bc1a043417b96150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:08<00:00,  8.56s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37a7a6f5f694d3dbf1d4399362a76ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e23f13927a4751b4e6e5f4213930e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:34<00:00, 34.33s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e10b051cc994d11a6fe9b4f88f65121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03811755911431786b8cbfd65e59a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:34<00:00, 34.23s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=360, training_loss=2.3068416171603734, metrics={'train_runtime': 1271.6642, 'train_samples_per_second': 4.523, 'train_steps_per_second': 0.283, 'total_flos': 0.0, 'train_loss': 2.3068416171603734, 'epoch': 1.0})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = trainer_mnr(fine_model, train_dataset, valid_dataset, args)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='221' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [131/131 2:10:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d4ecbebea64c3cb568f9970f782b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09fc4b54b0540009a08955f43fc4ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:35<00:00, 35.71s/it]\n"
     ]
    }
   ],
   "source": [
    "ev = get_ret_eval(test_dataset)\n",
    "test_dataset = test_dataset.select_columns([\"hypothesis\", \"premise\", \"label\"])\n",
    "\n",
    "ret = trainer.evaluate(eval_dataset=test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss 2.1264894008636475\n",
      "eval_cosine_accuracy@1 0.3333333333333333\n",
      "eval_cosine_accuracy@3 0.4444444444444444\n",
      "eval_cosine_accuracy@5 0.5555555555555556\n",
      "eval_cosine_accuracy@10 0.5555555555555556\n",
      "eval_cosine_precision@1 0.3333333333333333\n",
      "eval_cosine_precision@3 0.3703703703703704\n",
      "eval_cosine_precision@5 0.3111111111111111\n",
      "eval_cosine_precision@10 0.2222222222222222\n",
      "eval_cosine_recall@1 0.00942658164880387\n",
      "eval_cosine_recall@3 0.04062542395875729\n",
      "eval_cosine_recall@5 0.15918464251797584\n",
      "eval_cosine_recall@10 0.17709718265273822\n",
      "eval_cosine_ndcg@10 0.2937700524782729\n",
      "eval_cosine_mrr@10 0.39814814814814814\n",
      "eval_cosine_map@100 0.20914505536318057\n",
      "eval_runtime 272.435\n",
      "eval_samples_per_second 7.675\n",
      "eval_steps_per_second 0.481\n"
     ]
    }
   ],
   "source": [
    "for k, v in ret.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall@5': 0.026174972314507196, 'recall@10': 0.05922702104097453, 'recall@20': 0.12510077519379842, 'recall@50': 0.2801063122923588, 'normalized_recall@5': 0.2, 'normalized_recall@10': 0.22999999999999998, 'normalized_recall@20': 0.23499999999999996, 'normalized_recall@50': 0.3085714285714286, 'cluster_recall': 0.4}\n"
     ]
    }
   ],
   "source": [
    "ev = MyRecallEval(test_dataset)\n",
    "metrics = ev(trainer.model)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "36\n",
      "25\n",
      "30\n",
      "3\n",
      "25\n",
      "4\n",
      "1\n",
      "7\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def hihi(test_dataset):\n",
    "    corpus = dict(zip(test_dataset['premise'], test_dataset['premise']))\n",
    "    queries = dict(zip(test_dataset['hypothesis'], test_dataset['hypothesis']))\n",
    "    relevant_docs = defaultdict(list)\n",
    "\n",
    "    for k in range(len(test_dataset)):\n",
    "        if test_dataset['label'][k] > 0:\n",
    "            relevant_docs[test_dataset['hypothesis'][k]].append(test_dataset['premise'][k])\n",
    "    \n",
    "    for k, v in relevant_docs.items():\n",
    "        print(len(v))\n",
    "\n",
    "hihi(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
