{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copied from preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Domen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Domen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Domen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.883048\n",
       "1    0.116952\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "train_data_path = \"./data/English dataset/train.jsonl\"\n",
    "test_data_path = \"./data/English dataset/test.jsonl\"\n",
    "\n",
    "def preprocess_text(text): # From the labs\n",
    "\t# Tokenize the text into words\n",
    "\twords = word_tokenize(text.lower())  # Convert text to lowercase\n",
    "\n",
    "\t# Remove punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\twords = [word.translate(table) for word in words if word.isalpha()]\n",
    "\n",
    "\t# Remove stopwords\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\twords = [word for word in words if word not in stop_words]\n",
    "\n",
    "\t# Lemmatization\n",
    "\tlemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "\t# Join the words back into a string\n",
    "\tpreprocessed_text = ' '.join(lemmatized_words)\n",
    "\treturn preprocessed_text\n",
    "\n",
    "train_data = pd.DataFrame(datasets.load_dataset(\"json\", data_files=train_data_path)[\"train\"])\n",
    "test_dataset = pd.DataFrame(datasets.load_dataset(\"json\", data_files=test_data_path)[\"train\"])\n",
    "\n",
    "label_map = {\"Contradiction\": 1, \"Entailment\": 0, \"NotMentioned\": 0}\n",
    "train_data[\"label\"] = train_data[\"label\"].map(label_map)\n",
    "test_dataset[\"label\"] = test_dataset[\"label\"].map(label_map)\n",
    "\n",
    "train_data = train_data.drop(\"doc_id\", axis=1)\n",
    "train_data = train_data.drop(\"key\", axis=1)\n",
    "test_dataset = test_dataset.drop(\"doc_id\", axis=1)\n",
    "test_dataset = test_dataset.drop(\"key\", axis=1)\n",
    "\n",
    "train_data[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section was already in tims file so when you join the files you can just delete the upper preprocessing section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My adition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_splitter(p, text_lim, overlap=250, allowed_delimiters=\" ,.?!\"):\n",
    "    i = text_lim\n",
    "    while not p[i] in allowed_delimiters and i > 0:\n",
    "        i -= 1\n",
    "    p1 = p[:i]\n",
    "\n",
    "    d = len(p) - i\n",
    "    if d < text_lim-overlap:\n",
    "        j = text_lim-overlap\n",
    "        while not p[j] in allowed_delimiters and j > 0:\n",
    "            j += 1\n",
    "        p2 = p[j:]\n",
    "        return [p1,p2]\n",
    "    else:\n",
    "        return p1 + text_splitter(p[(i-overlap):], text_lim, overlap)\n",
    "\n",
    "def dataset_splitter(df, token_lim = 768, overlap=50, allowed_delimiters=\" ,.?!\"): # ensures the premises are roughly within the token limit\n",
    "    text_lim = int(token_lim * 3.5)\n",
    "    overlap = int(overlap*3.5)\n",
    "    to_app = []\n",
    "    for i,r in df.iterrows():\n",
    "        if len(r['premise']) > text_lim:\n",
    "            seg = text_splitter(r['premise'], text_lim, overlap=overlap, allowed_delimiters=allowed_delimiters)\n",
    "\n",
    "            for s in seg:\n",
    "                nr = {'premise': s, 'hypothesis': r['hypothesis'], 'label': r['label']}\n",
    "                to_app.append(nr)\n",
    "            \n",
    "            df.drop(i)\n",
    "    \n",
    "    df.append(pd.DataFrame(to_app))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2091\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ds = Dataset.from_pandas(train_data)\n",
    "ds = ds.select_columns([\"hypothesis\", \"premise\", \"label\"])\n",
    "ds = ds.select_columns([\"hypothesis\", \"premise\", \"label\"])\n",
    "\n",
    "dss = ds.train_test_split(0.2, seed=42)\n",
    "train_dataset = dss['train']\n",
    "valid_dataset = dss['test']\n",
    "test_dataset = Dataset.from_pandas(test_dataset)\n",
    "\n",
    "test_corpus = test_dataset['premise']\n",
    "test_hypothesis = test_dataset['hypothesis']\n",
    "print(len(test_hypothesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5752 1439\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(valid_dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_ret_eval(test_dataset):\n",
    "    corpus = dict(zip(test_dataset['premise'], test_dataset['premise']))\n",
    "    queries = dict(zip(test_dataset['hypothesis'], test_dataset['hypothesis']))\n",
    "    relevant_docs = defaultdict(list)\n",
    "\n",
    "    for k in range(len(test_dataset)):\n",
    "        if test_dataset['label'][k] > 0:\n",
    "            relevant_docs[test_dataset['hypothesis'][k]].append(test_dataset['premise'][k])\n",
    "    \n",
    "\n",
    "    inf_ret_ev = InformationRetrievalEvaluator(\n",
    "        queries= queries,\n",
    "        corpus = corpus,\n",
    "        relevant_docs = relevant_docs,\n",
    "        #similarity_fn_names= [\"cosine\"],\n",
    "        show_progress_bar=True,\n",
    "        batch_size= 8,\n",
    "        #main_score_function=\"Recall@10\"\n",
    "    )\n",
    "\n",
    "    return inf_ret_ev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "def get_bin_eval(test_dataset):\n",
    "    \"\"\"\n",
    "        BinnaryClassification returns: F1, Percision, Recall, Avg Percision, Matthews Correlation, \n",
    "    \"\"\"\n",
    "    bin_acc_ev = BinaryClassificationEvaluator(\n",
    "        sentences1= test_dataset['hypothesis'],\n",
    "        sentences2= test_dataset['premise'],\n",
    "        labels= test_dataset['label'],\n",
    "        similarity_fn_names= [\"cosine\", \"dot\"],\n",
    "        show_progress_bar= True,\n",
    "        batch_size= 8\n",
    "    )\n",
    "    return bin_acc_ev"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import BinaryClassificationEvaluator\n",
    "from collections import defaultdict\n",
    "\n",
    "def eval_full_inbuilt(model, test_dataset):\n",
    "    \"\"\"\n",
    "        BinnaryClassification returns: F1, Percision, Recall, Avg Percision, Matthews Correlation, \n",
    "    \"\"\"\n",
    "\n",
    "    bin_acc_ev = get_bin_eval(test_dataset)\n",
    "\n",
    "    inf_ret_ev = get_ret_eval(test_dataset)\n",
    "\n",
    "    result = {}\n",
    "    result[\"BinaryClassificaton\"] = bin_acc_ev(model)\n",
    "    result[\"InformationRetrieval\"] = inf_ret_ev(model)\n",
    "\n",
    "    for meth, d in result.items():\n",
    "        print()\n",
    "        print(meth, \": \")\n",
    "        for k, v in d.items():\n",
    "            print(k, \": \",v)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model\n",
    "- Straight from the box, unmodified\n",
    "-  [msmarco-MiniLM-L6-cos-v5](https://huggingface.co/sentence-transformers/msmarco-MiniLM-L6-cos-v5) Trained specificly for query-passage retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at .\\models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "model_name = \".\\models\\jina-embeddings-v2-small-en\" \n",
    "base_model = SentenceTransformer(model_name, model_kwargs={\"dtype\": \"float16\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " float16 should speed up the model, while having minimal impact on preformance: [documentation](https://www.sbert.net/docs/sentence_transformer/usage/efficiency.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the base model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n I | I i\\nI I| L\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    " I | I i\n",
    "I I| L\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer\n",
    "\n",
    "fine_model = base_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup of Trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "k = 10\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"models/tuned_model\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    seed=42,\n",
    "    metric_for_best_model=f\"eval_recall@{k}\",\n",
    "    greater_is_better=False,\n",
    "  \tload_best_model_at_end=True,\n",
    "  \tweight_decay=0.01,\n",
    "    \n",
    "    #warmup_ratio=0.1,\n",
    "    fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "    #batch_sampler=BatchSamplers.NO_DUPLICATES,  # losses that use \"in-batch negatives\" benefit from no duplicates\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50, # how often we eval\n",
    "    #save_strategy=\"best\",\n",
    "    torch_empty_cache_steps = None,\n",
    "    save_steps=50,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    run_name=\"mpnet-base-all-nli-triplet\",  # Will be used in W&B if `wandb` is installed\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contrastive loss** Used for binary labled pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import OnlineContrastiveLoss\n",
    "\n",
    "def trainer_cl(m, train_dataset, valid_dataset, args):\n",
    "    td = {''}\n",
    "    loss = OnlineContrastiveLoss(m)\n",
    "\n",
    "    evaluator = get_ret_eval(valid_dataset)\n",
    "\n",
    "    trainer = SentenceTransformerTrainer(\n",
    "        model = m,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        loss=loss,\n",
    "        args=args\n",
    "    )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this if using a trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ProjectsSSD\\School\\IS\\IS2\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  8/630 04:01 < 6:58:05, 0.02 it/s, Epoch 0.01/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = trainer_cl(fine_model, train_dataset, valid_dataset, args)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
