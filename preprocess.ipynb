{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3be0ea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\timna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\timna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\timna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tabulate import tabulate\n",
    "\n",
    "from transformers import Trainer\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "train_data_path = \"./data/English dataset/train.jsonl\"\n",
    "test_data_path = \"./data/English dataset/test.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a3395f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_report_dict(report):\n",
    "\treport_df = pd.DataFrame(report).transpose()\n",
    "\treport_df = report_df.round(3)\n",
    "\n",
    "\tclass_metrics = report_df.iloc[:-3, :].copy()\n",
    "\n",
    "\tsummary_metrics = report_df.iloc[-3:, :].copy()\n",
    "\tsummary_metrics = summary_metrics.drop(columns=['support'])\n",
    "\n",
    "\tprint(\"CLASS PERFORMANCE\")\n",
    "\tprint(tabulate(class_metrics, headers='keys', tablefmt='heavy_outline', numalign=\"center\"))\n",
    "\tprint()\n",
    "\tprint(\"GLOBAL AVERAGES\")\n",
    "\tprint(tabulate(summary_metrics, headers='keys', tablefmt='heavy_outline', numalign=\"center\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632dab40",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454c9e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text): # From the labs\n",
    "\t# Tokenize the text into words\n",
    "\twords = word_tokenize(text.lower())  # Convert text to lowercase\n",
    "\n",
    "\t# Remove punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\twords = [word.translate(table) for word in words if word.isalpha()]\n",
    "\n",
    "\t# Remove stopwords\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\twords = [word for word in words if word not in stop_words]\n",
    "\n",
    "\t# Lemmatization\n",
    "\tlemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "\t# Join the words back into a string\n",
    "\tpreprocessed_text = ' '.join(lemmatized_words)\n",
    "\treturn preprocessed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d6658",
   "metadata": {},
   "source": [
    "(We load the dataset. We join togeder eintailment and not mentioned, so we can focus on predicting only if something is a contradiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01b42342",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(datasets.load_dataset(\"json\", data_files=train_data_path)[\"train\"])\n",
    "test_data = pd.DataFrame(datasets.load_dataset(\"json\", data_files=test_data_path)[\"train\"])\n",
    "\n",
    "label_map = {\"Contradiction\": 1, \"Entailment\": 0, \"NotMentioned\": 0}\n",
    "train_data[\"label\"] = train_data[\"label\"].map(label_map)\n",
    "test_data[\"label\"] = test_data[\"label\"].map(label_map)\n",
    "\n",
    "train_data = train_data.drop(\"doc_id\", axis=1)\n",
    "train_data = train_data.drop(\"key\", axis=1)\n",
    "test_data = test_data.drop(\"doc_id\", axis=1)\n",
    "test_data = test_data.drop(\"key\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f84f7b3",
   "metadata": {},
   "source": [
    "(After we load the dataset, we inspect it for class inbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc257598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "proportion",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a5795828-37ec-49cb-bc4f-0c3310042985",
       "rows": [
        [
         "0",
         "0.883048254762898"
        ],
        [
         "1",
         "0.11695174523710193"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "label\n",
       "0    0.883048\n",
       "1    0.116952\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf41521e",
   "metadata": {},
   "source": [
    "(We can see that most of the data isn't contradictions. The data is quite imbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc29f7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest premise:  3098\n",
      "Longest hypothesis:  162\n",
      "---------------------------------\n",
      "Mean premise length:  296.27826449728826\n",
      "+1 std:  651.2505192635402\n",
      "+2 std:  1006.2227740297922\n",
      "+3 std:  1361.1950287960442\n"
     ]
    }
   ],
   "source": [
    "longest_premise = max(train_data['premise'].apply(len).max(), test_data['premise'].apply(len).max())\n",
    "longest_hypotises = max(train_data['hypothesis'].apply(len).max(), test_data['hypothesis'].apply(len).max())\n",
    "longest_sentance = max(longest_premise, longest_hypotises)\n",
    "print(\"Longest premise: \", longest_premise)\n",
    "print(\"Longest hypothesis: \", longest_hypotises)\n",
    "\n",
    "print(\"---------------------------------\")\n",
    "mean = np.mean(train_data['premise'].apply(len))\n",
    "std = np.std(train_data['premise'].apply(len))\n",
    "\n",
    "print(\"Mean premise length: \", mean)\n",
    "print(\"+1 std: \", mean+std)\n",
    "print(\"+2 std: \", mean+2*std)\n",
    "print(\"+3 std: \", mean+3*std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79f9a2d",
   "metadata": {},
   "source": [
    "(We inspect the lenght of the data. We do this to see if it would be beneficial only keeping smaller sizes of the data, so we can cleanly feed it into BERT model. We conclude that we would need to thin our data too much to be worth it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76db4a51",
   "metadata": {},
   "source": [
    "# Traditional ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e859aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_premise = TfidfVectorizer()\n",
    "vectorizer_hypothesis = TfidfVectorizer()\n",
    "\n",
    "train_data_vectorised = train_data.copy()\n",
    "\n",
    "X_premise= vectorizer_premise.fit_transform(train_data[\"premise\"])\n",
    "X_hypothesis = vectorizer_hypothesis.fit_transform(train_data[\"hypothesis\"])\n",
    "train_data_vectorised = hstack([X_premise, X_hypothesis])\n",
    "\n",
    "Y_premise = vectorizer_premise.transform(test_data[\"premise\"])\n",
    "Y_hypothesis = vectorizer_hypothesis.transform(test_data[\"hypothesis\"])\n",
    "test_data_vectorised = hstack([Y_premise, Y_hypothesis])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceb5a7d",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "732ddec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┓\n",
      "┃ Hyperparameter   ┃ Value    ┃\n",
      "┣━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━┫\n",
      "┃ solver           ┃ saga     ┃\n",
      "┃ l1_ratio         ┃ 0.5      ┃\n",
      "┃ class_weight     ┃ balanced ┃\n",
      "┃ C                ┃ 50       ┃\n",
      "┗━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "grid_serch_dict = {\n",
    "\t\"l1_ratio\": [0, 0.5, 1],\n",
    "\t\"C\": [0.1, 0.5, 1.0, 2.0, 10, 50],\n",
    "\t\"class_weight\": [None, \"balanced\"],\n",
    "\t\"solver\": [\"saga\"]\n",
    "}\n",
    "\n",
    "logreg_model = RandomizedSearchCV(LogisticRegression(max_iter=5000), grid_serch_dict, n_iter=10, cv=3, scoring='f1')\n",
    "logreg_model.fit(train_data_vectorised, train_data[\"label\"])\n",
    "\n",
    "predictions = logreg_model.predict(test_data_vectorised)\n",
    "\n",
    "display_params = [[k, str(v)] for k, v in logreg_model.best_params_.items()]\n",
    "print(tabulate(display_params, headers=[\"Hyperparameter\", \"Value\"], tablefmt=\"heavy_outline\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a00d6280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃    0.982    ┃  0.974   ┃   0.978    ┃   1871    ┃\n",
      "┃ 1  ┃    0.795    ┃  0.845   ┃   0.819    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.961    ┃  0.961   ┃   0.961    ┃\n",
      "┃ macro avg    ┃    0.888    ┃   0.91   ┃   0.899    ┃\n",
      "┃ weighted avg ┃    0.962    ┃  0.961   ┃   0.961    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "report_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "pretty_print_report_dict(report_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24f1a2e",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b01d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┓\n",
      "┃ Hyperparameter    ┃ Value    ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━┫\n",
      "┃ n_estimators      ┃ 50       ┃\n",
      "┃ min_samples_split ┃ 2        ┃\n",
      "┃ max_depth         ┃ None     ┃\n",
      "┃ class_weight      ┃ balanced ┃\n",
      "┗━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "grid_serch_dict = {\n",
    "\t\"n_estimators\": [50, 100, 200],\n",
    "\t\"max_depth\": [None, 5, 10, 20],\n",
    "\t\"min_samples_split\": [2, 5, 10, 20, 50],\n",
    "\t\"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "rf_model = RandomizedSearchCV(RandomForestClassifier(random_state=67), grid_serch_dict, n_iter=15, cv=3, scoring='f1')\n",
    "rf_model.fit(train_data_vectorised, train_data[\"label\"])\n",
    "\n",
    "predictions = rf_model.predict(test_data_vectorised)\n",
    "\n",
    "display_params = [[k, str(v)] for k, v in rf_model.best_params_.items()]\n",
    "print(tabulate(display_params, headers=[\"Hyperparameter\", \"Value\"], tablefmt=\"heavy_outline\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e284a8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃    0.975    ┃   0.99   ┃   0.983    ┃   1871    ┃\n",
      "┃ 1  ┃    0.905    ┃  0.782   ┃   0.839    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.968    ┃  0.968   ┃   0.968    ┃\n",
      "┃ macro avg    ┃    0.94     ┃  0.886   ┃   0.911    ┃\n",
      "┃ weighted avg ┃    0.967    ┃  0.968   ┃   0.967    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "report_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "pretty_print_report_dict(report_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f15acf",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eaf13b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┓\n",
      "┃ Hyperparameter   ┃ Value   ┃\n",
      "┣━━━━━━━━━━━━━━━━━━╋━━━━━━━━━┫\n",
      "┃ kernel           ┃ rbf     ┃\n",
      "┃ class_weight     ┃ None    ┃\n",
      "┃ C                ┃ 10      ┃\n",
      "┗━━━━━━━━━━━━━━━━━━┻━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "grid_serch_dict = {\n",
    "\t\"C\": [0.1, 0.5, 1.0, 2.0, 10, 50],\n",
    "\t\"kernel\": [\"linear\", \"sigmoid\", \"rbf\"],\n",
    "\t\"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "svm_model = RandomizedSearchCV(SVC(), grid_serch_dict, n_iter=10, cv=3, scoring='f1')\n",
    "svm_model.fit(train_data_vectorised, train_data[\"label\"])\n",
    "\n",
    "predictions = svm_model.predict(test_data_vectorised)\n",
    "\n",
    "display_params = [[k, str(v)] for k, v in svm_model.best_params_.items()]\n",
    "print(tabulate(display_params, headers=[\"Hyperparameter\", \"Value\"], tablefmt=\"heavy_outline\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cebb30a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃    0.981    ┃  0.989   ┃   0.985    ┃   1871    ┃\n",
      "┃ 1  ┃    0.898    ┃  0.841   ┃   0.869    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.973    ┃  0.973   ┃   0.973    ┃\n",
      "┃ macro avg    ┃    0.94     ┃  0.915   ┃   0.927    ┃\n",
      "┃ weighted avg ┃    0.973    ┃  0.973   ┃   0.973    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "report_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "pretty_print_report_dict(report_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5d3892",
   "metadata": {},
   "source": [
    "# Transformer-Based Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec85221",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7661d560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/longformer-mini-1024 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "\n",
    "def preprocess_function(examples):\n",
    "\tinputs = tokenizer(examples[\"premise\"], examples[\"hypothesis\"], \n",
    "\t\t\tmax_length=1024, truncation=\"only_first\", padding=\"max_length\")\n",
    "\n",
    "\tglobal_attention_mask = [[0] * len(ids) for ids in inputs[\"input_ids\"]]\n",
    "\n",
    "\tfor mask in global_attention_mask:\n",
    "\t\tmask[0] = 1 \n",
    "\t\t\n",
    "\tinputs[\"global_attention_mask\"] = global_attention_mask\n",
    "\treturn inputs\n",
    "\n",
    "model_name = \"kiddothe2b/longformer-mini-1024\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ce84564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7191/7191 [00:09<00:00, 774.18 examples/s]\n",
      "Map: 100%|██████████| 2091/2091 [00:02<00:00, 767.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "eval_dataset = Dataset.from_pandas(test_data)\n",
    "tokenized_eval_dataset = eval_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "975d4b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ni treniran\n"
     ]
    }
   ],
   "source": [
    "RUN = False\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import f1_score\n",
    "from torch import nn\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "\tdef __init__(self, *args, class_weights=None, **kwargs):\n",
    "\t\tsuper().__init__(*args, **kwargs)\n",
    "\t\tif class_weights is not None:\n",
    "\t\t\tself.class_weights = torch.tensor(class_weights, dtype=torch.float).to(self.args.device)\n",
    "\t\telse:\n",
    "\t\t\tself.class_weights = None\n",
    "\n",
    "\tdef compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None, **kwargs):\n",
    "\t\tlabels = inputs.get(\"labels\")\n",
    "\t\toutputs = model(**inputs)\n",
    "\t\tlogits = outputs.get(\"logits\")\n",
    "\t\t\n",
    "\t\tif self.class_weights is not None:\n",
    "\t\t\tloss_fct = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "\t\t\tloss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "\t\telse:\n",
    "\t\t\t# Fallback to default loss if no weights are provided\n",
    "\t\t\tloss = outputs.loss if isinstance(outputs, dict) else outputs[0]\n",
    "\t\t\t\n",
    "\t\treturn (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\tlogits, labels = eval_pred\n",
    "\tpredictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "\tf1 = f1_score(labels, predictions, pos_label=1, average='binary')\n",
    "\treturn {\"f1_score_class_1\": f1}\n",
    "\n",
    "class_weights = [1.0, 9.0] # Weight class 0, weight class 1\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "\toutput_dir=\"./artifacts\",\n",
    "\tlearning_rate=2e-4,\n",
    "\tper_device_train_batch_size=2,\n",
    "\tgradient_accumulation_steps=16,\n",
    "\tnum_train_epochs=2,\n",
    "\tweight_decay=0.01,\n",
    "\tsave_strategy=\"steps\",\n",
    "\tsave_steps=50,\n",
    "\tsave_total_limit=3, \n",
    "\tload_best_model_at_end=True,\n",
    "\tmetric_for_best_model=\"f1_score_class_1\", \n",
    "\teval_strategy=\"steps\",\n",
    "\teval_steps=50,\n",
    "\tgreater_is_better=True,\n",
    "\tresume_from_checkpoint=False\n",
    ")\n",
    "\n",
    "\n",
    "path = \"./trained_model_ex3_f1_class1_weighted\"\n",
    "if (not os.path.exists(path) and RUN):\n",
    "\ttrainer = WeightedTrainer(\n",
    "\t\tmodel=model,\n",
    "\t\targs=training_args,\n",
    "\t\ttrain_dataset=tokenized_train_dataset,\n",
    "\t\teval_dataset=tokenized_eval_dataset,\n",
    "\t\tcompute_metrics=compute_metrics,\n",
    "\t\tclass_weights=class_weights,\n",
    "\t)\n",
    "\n",
    "\ttrainer.train(resume_from_checkpoint=True)\n",
    "\n",
    "\ttokenizer.save_pretrained(path)\n",
    "\ttrainer.save_model(path)\n",
    "else:\n",
    "\tprint(\"Model ni treniran\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3089f583",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9080e36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃    0.981    ┃  0.972   ┃   0.976    ┃   1871    ┃\n",
      "┃ 1  ┃    0.776    ┃  0.836   ┃   0.805    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.957    ┃  0.957   ┃   0.957    ┃\n",
      "┃ macro avg    ┃    0.878    ┃  0.904   ┃   0.891    ┃\n",
      "┃ weighted avg ┃    0.959    ┃  0.957   ┃   0.958    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "path = \"trained_model_ex3_precision_class1_v1\"\n",
    "if (os.path.exists(path)):\n",
    "\tmodel = AutoModelForSequenceClassification.from_pretrained(path, num_labels=2)\n",
    "\n",
    "\ttrainer = Trainer(model=model)\n",
    "\tpredictions_procentages = trainer.predict(tokenized_eval_dataset)[0]\n",
    "\tpredictions = predictions_procentages.argmax(-1)\n",
    "\treport_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "\tpretty_print_report_dict(report_dict)\n",
    "else:\n",
    "\tprint(\"Model not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63650b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃    0.935    ┃  0.975   ┃   0.955    ┃   1871    ┃\n",
      "┃ 1  ┃    0.667    ┃  0.427   ┃   0.521    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.917    ┃  0.917   ┃   0.917    ┃\n",
      "┃ macro avg    ┃    0.801    ┃  0.701   ┃   0.738    ┃\n",
      "┃ weighted avg ┃    0.907    ┃  0.917   ┃   0.909    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "path = \"trained_model_ex3_v2_macro_f1_v1\"\n",
    "if (os.path.exists(path)):\n",
    "\tmodel = AutoModelForSequenceClassification.from_pretrained(path, num_labels=2)\n",
    "\n",
    "\ttrainer = Trainer(model=model)\n",
    "\tpredictions_procentages = trainer.predict(tokenized_eval_dataset)[0]\n",
    "\tpredictions = predictions_procentages.argmax(-1)\n",
    "\treport_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "\tpretty_print_report_dict(report_dict)\n",
    "else:\n",
    "\tprint(\"Model not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39c4d7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃    0.981    ┃  0.975   ┃   0.978    ┃   1871    ┃\n",
      "┃ 1  ┃    0.797    ┃  0.836   ┃   0.816    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.96     ┃   0.96   ┃    0.96    ┃\n",
      "┃ macro avg    ┃    0.889    ┃  0.906   ┃   0.897    ┃\n",
      "┃ weighted avg ┃    0.961    ┃   0.96   ┃   0.961    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "path = \"trained_model_ex3_f1_class1_weighted\"\n",
    "if (os.path.exists(path)):\n",
    "\tmodel = AutoModelForSequenceClassification.from_pretrained(path, num_labels=2)\n",
    "\n",
    "\ttrainer = Trainer(model=model)\n",
    "\tpredictions_procentages = trainer.predict(tokenized_eval_dataset)[0]\n",
    "\tpredictions = predictions_procentages.argmax(-1)\n",
    "\treport_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "\tpretty_print_report_dict(report_dict)\n",
    "else:\n",
    "\tprint(\"Model not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "293bd42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃    0.982    ┃  0.974   ┃   0.978    ┃   1871    ┃\n",
      "┃ 1  ┃    0.791    ┃  0.845   ┃   0.818    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.96     ┃   0.96   ┃    0.96    ┃\n",
      "┃ macro avg    ┃    0.887    ┃   0.91   ┃   0.898    ┃\n",
      "┃ weighted avg ┃    0.962    ┃   0.96   ┃   0.961    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "path = \"trained_model_ex3_f1_class1_weighted_2_epoc\"\n",
    "if (os.path.exists(path)):\n",
    "\tmodel = AutoModelForSequenceClassification.from_pretrained(path, num_labels=2)\n",
    "\n",
    "\ttrainer = Trainer(model=model)\n",
    "\tpredictions_procentages = trainer.predict(tokenized_eval_dataset)[0]\n",
    "\tpredictions = predictions_procentages.argmax(-1)\n",
    "\treport_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "\tpretty_print_report_dict(report_dict)\n",
    "else:\n",
    "\tprint(\"Model not found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
