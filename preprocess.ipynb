{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3be0ea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Domen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Domen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Domen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Domen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tabulate import tabulate\n",
    "\n",
    "from transformers import Trainer\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "train_data_path = \"./data/English dataset/train.jsonl\"\n",
    "test_data_path = \"./data/English dataset/test.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9a3395f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_report_dict(report):\n",
    "\treport_df = pd.DataFrame(report).transpose()\n",
    "\treport_df = report_df.round(3)\n",
    "\n",
    "\tclass_metrics = report_df.iloc[:-3, :].copy()\n",
    "\n",
    "\tsummary_metrics = report_df.iloc[-3:, :].copy()\n",
    "\tsummary_metrics = summary_metrics.drop(columns=['support'])\n",
    "\n",
    "\tprint(\"CLASS PERFORMANCE\")\n",
    "\tprint(tabulate(class_metrics, headers='keys', tablefmt='heavy_outline', numalign=\"center\"))\n",
    "\tprint()\n",
    "\tprint(\"GLOBAL AVERAGES\")\n",
    "\tprint(tabulate(summary_metrics, headers='keys', tablefmt='heavy_outline', numalign=\"center\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "632dab40",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "454c9e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text): # From the labs\n",
    "\t# Tokenize the text into words\n",
    "\twords = word_tokenize(text.lower())  # Convert text to lowercase\n",
    "\n",
    "\t# Remove punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\twords = [word.translate(table) for word in words if word.isalpha()]\n",
    "\n",
    "\t# Remove stopwords\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\twords = [word for word in words if word not in stop_words]\n",
    "\n",
    "\t# Lemmatization\n",
    "\tlemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "\t# Join the words back into a string\n",
    "\tpreprocessed_text = ' '.join(lemmatized_words)\n",
    "\treturn preprocessed_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f72d6658",
   "metadata": {},
   "source": [
    "(We load the dataset. We join togeder eintailment and not mentioned, so we can focus on predicting only if something is a contradiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "01b42342",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(datasets.load_dataset(\"json\", data_files=train_data_path)[\"train\"])\n",
    "test_data = pd.DataFrame(datasets.load_dataset(\"json\", data_files=test_data_path)[\"train\"])\n",
    "\n",
    "label_map = {\"Contradiction\": 1, \"Entailment\": 0, \"NotMentioned\": 0}\n",
    "train_data[\"label\"] = train_data[\"label\"].map(label_map)\n",
    "test_data[\"label\"] = test_data[\"label\"].map(label_map)\n",
    "\n",
    "train_data = train_data.drop(\"doc_id\", axis=1)\n",
    "train_data = train_data.drop(\"key\", axis=1)\n",
    "test_data = test_data.drop(\"doc_id\", axis=1)\n",
    "test_data = test_data.drop(\"key\", axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f84f7b3",
   "metadata": {},
   "source": [
    "(After we load the dataset, we inspect it for class inbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "fc257598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.883048\n",
       "1    0.116952\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf41521e",
   "metadata": {},
   "source": [
    "(We can see that most of the data isn't contradictions. The data is quite imbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fc29f7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest premise:  3098\n",
      "Longest hypothesis:  162\n",
      "---------------------------------\n",
      "Mean premise length:  296.27826449728826\n",
      "+1 std:  651.2505192635402\n",
      "+2 std:  1006.2227740297922\n",
      "+3 std:  1361.1950287960442\n"
     ]
    }
   ],
   "source": [
    "longest_premise = max(train_data['premise'].apply(len).max(), test_data['premise'].apply(len).max())\n",
    "longest_hypotises = max(train_data['hypothesis'].apply(len).max(), test_data['hypothesis'].apply(len).max())\n",
    "longest_sentance = max(longest_premise, longest_hypotises)\n",
    "print(\"Longest premise: \", longest_premise)\n",
    "print(\"Longest hypothesis: \", longest_hypotises)\n",
    "\n",
    "print(\"---------------------------------\")\n",
    "mean = np.mean(train_data['premise'].apply(len))\n",
    "std = np.std(train_data['premise'].apply(len))\n",
    "\n",
    "print(\"Mean premise length: \", mean)\n",
    "print(\"+1 std: \", mean+std)\n",
    "print(\"+2 std: \", mean+2*std)\n",
    "print(\"+3 std: \", mean+3*std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a79f9a2d",
   "metadata": {},
   "source": [
    "(We inspect the lenght of the data. We do this to see if it would be beneficial only keeping smaller sizes of the data, so we can cleanly feed it into BERT model. We conclude that we would need to thin our data too much to be worth it)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76db4a51",
   "metadata": {},
   "source": [
    "# Traditional ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7e859aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_preprocessed = train_data.copy()\n",
    "test_data_preprocessed = test_data.copy()\n",
    "\n",
    "train_data_preprocessed[\"premise\"] = train_data_preprocessed[\"premise\"].map(preprocess_text)\n",
    "train_data_preprocessed[\"hypothesis\"] = train_data_preprocessed[\"hypothesis\"].map(preprocess_text)\n",
    "\n",
    "test_data_preprocessed[\"premise\"] = test_data_preprocessed[\"premise\"].map(preprocess_text)\n",
    "test_data_preprocessed[\"hypothesis\"] = test_data_preprocessed[\"hypothesis\"].map(preprocess_text)\n",
    "\n",
    "vectorizer_premise = TfidfVectorizer()\n",
    "vectorizer_hypothesis = TfidfVectorizer()\n",
    "\n",
    "train_data_vectorised = train_data.copy()\n",
    "\n",
    "X_premise= vectorizer_premise.fit_transform(train_data[\"premise\"])\n",
    "X_hypothesis = vectorizer_hypothesis.fit_transform(train_data[\"hypothesis\"])\n",
    "train_data_vectorised = hstack([X_premise, X_hypothesis])\n",
    "\n",
    "Y_premise = vectorizer_premise.transform(test_data_preprocessed[\"premise\"])\n",
    "Y_hypothesis = vectorizer_hypothesis.transform(test_data_preprocessed[\"hypothesis\"])\n",
    "test_data_vectorised = hstack([Y_premise, Y_hypothesis])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ceb5a7d",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "732ddec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timna\\Desktop\\SkupnoAng\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┓\n",
      "┃ Hyperparameter   ┃ Value    ┃\n",
      "┣━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━┫\n",
      "┃ solver           ┃ saga     ┃\n",
      "┃ l1_ratio         ┃ 1        ┃\n",
      "┃ class_weight     ┃ balanced ┃\n",
      "┃ C                ┃ 50       ┃\n",
      "┗━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "grid_serch_dict = {\n",
    "\t\"l1_ratio\": [0, 0.5, 1],\n",
    "\t\"C\": [0.1, 0.5, 1.0, 2.0, 10, 50],\n",
    "\t\"class_weight\": [None, \"balanced\"],\n",
    "\t\"solver\": [\"saga\"]\n",
    "}\n",
    "\n",
    "logreg_model = RandomizedSearchCV(LogisticRegression(max_iter=5000), grid_serch_dict, n_iter=10, cv=3, scoring='f1')\n",
    "logreg_model.fit(train_data_vectorised, train_data[\"label\"])\n",
    "\n",
    "predictions = logreg_model.predict(test_data_vectorised)\n",
    "\n",
    "display_params = [[k, str(v)] for k, v in logreg_model.best_params_.items()]\n",
    "print(tabulate(display_params, headers=[\"Hyperparameter\", \"Value\"], tablefmt=\"heavy_outline\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a00d6280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃    0.926    ┃  0.997   ┃    0.96    ┃   1871    ┃\n",
      "┃ 1  ┃    0.923    ┃  0.327   ┃   0.483    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.926    ┃  0.926   ┃   0.926    ┃\n",
      "┃ macro avg    ┃    0.925    ┃  0.662   ┃   0.722    ┃\n",
      "┃ weighted avg ┃    0.926    ┃  0.926   ┃    0.91    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "report_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "pretty_print_report_dict(report_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c24f1a2e",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "414b01d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┓\n",
      "┃ Hyperparameter    ┃ Value   ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━┫\n",
      "┃ n_estimators      ┃ 200     ┃\n",
      "┃ min_samples_split ┃ 5       ┃\n",
      "┃ max_depth         ┃ None    ┃\n",
      "┃ class_weight      ┃ None    ┃\n",
      "┗━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "grid_serch_dict = {\n",
    "\t\"n_estimators\": [50, 100, 200],\n",
    "\t\"max_depth\": [None, 5, 10, 20],\n",
    "\t\"min_samples_split\": [2, 5, 10, 20, 50],\n",
    "\t\"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "rf_model = RandomizedSearchCV(RandomForestClassifier(random_state=67), grid_serch_dict, n_iter=15, cv=3, scoring='f1')\n",
    "rf_model.fit(train_data_vectorised, train_data[\"label\"])\n",
    "\n",
    "predictions = rf_model.predict(test_data_vectorised)\n",
    "\n",
    "display_params = [[k, str(v)] for k, v in rf_model.best_params_.items()]\n",
    "print(tabulate(display_params, headers=[\"Hyperparameter\", \"Value\"], tablefmt=\"heavy_outline\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e284a8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃    0.923    ┃    1     ┃    0.96    ┃   1871    ┃\n",
      "┃ 1  ┃      1      ┃  0.295   ┃   0.456    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.926    ┃  0.926   ┃   0.926    ┃\n",
      "┃ macro avg    ┃    0.962    ┃  0.648   ┃   0.708    ┃\n",
      "┃ weighted avg ┃    0.932    ┃  0.926   ┃   0.907    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "report_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "pretty_print_report_dict(report_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75f15acf",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "eaf13b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┓\n",
      "┃ Hyperparameter   ┃ Value   ┃\n",
      "┣━━━━━━━━━━━━━━━━━━╋━━━━━━━━━┫\n",
      "┃ kernel           ┃ rbf     ┃\n",
      "┃ class_weight     ┃ None    ┃\n",
      "┃ C                ┃ 10      ┃\n",
      "┗━━━━━━━━━━━━━━━━━━┻━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "grid_serch_dict = {\n",
    "\t\"C\": [0.1, 0.5, 1.0, 2.0, 10, 50],\n",
    "\t\"kernel\": [\"linear\", \"sigmoid\", \"rbf\"],\n",
    "\t\"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "svm_model = RandomizedSearchCV(SVC(), grid_serch_dict, n_iter=10, cv=3, scoring='f1')\n",
    "svm_model.fit(train_data_vectorised, train_data[\"label\"])\n",
    "\n",
    "predictions = svm_model.predict(test_data_vectorised)\n",
    "\n",
    "display_params = [[k, str(v)] for k, v in svm_model.best_params_.items()]\n",
    "print(tabulate(display_params, headers=[\"Hyperparameter\", \"Value\"], tablefmt=\"heavy_outline\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "cebb30a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃    0.946    ┃  0.997   ┃   0.971    ┃   1871    ┃\n",
      "┃ 1  ┃    0.95     ┃  0.518   ┃   0.671    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.946    ┃  0.946   ┃   0.946    ┃\n",
      "┃ macro avg    ┃    0.948    ┃  0.757   ┃   0.821    ┃\n",
      "┃ weighted avg ┃    0.947    ┃  0.946   ┃   0.939    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "report_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "pretty_print_report_dict(report_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d5d3892",
   "metadata": {},
   "source": [
    "# Transformer-Based Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ec85221",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7661d560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/longformer-mini-1024 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "\n",
    "def preprocess_function(examples):\n",
    "\tinputs = tokenizer(examples[\"premise\"], examples[\"hypothesis\"], \n",
    "\t\t\tmax_length=1024, truncation=\"only_first\", padding=\"max_length\")\n",
    "\n",
    "\tglobal_attention_mask = [[0] * len(ids) for ids in inputs[\"input_ids\"]]\n",
    "\n",
    "\tfor mask in global_attention_mask:\n",
    "\t\tmask[0] = 1 \n",
    "\t\t\n",
    "\tinputs[\"global_attention_mask\"] = global_attention_mask\n",
    "\treturn inputs\n",
    "\n",
    "model_name = \"kiddothe2b/longformer-mini-1024\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce84564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7191/7191 [00:09<00:00, 777.74 examples/s]\n",
      "Map: 100%|██████████| 2091/2091 [00:02<00:00, 814.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "dataset_split = tokenized_train_dataset.train_test_split(test_size=0.1)\n",
    "tokenized_train_dataset = dataset_split[\"train\"]\n",
    "tokenized_eval_dataset = dataset_split[\"test\"]\n",
    "\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975d4b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not trained\n"
     ]
    }
   ],
   "source": [
    "RUN = False\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import f1_score\n",
    "from torch import nn\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "\tdef __init__(self, *args, class_weights=None, **kwargs):\n",
    "\t\tsuper().__init__(*args, **kwargs)\n",
    "\t\tif class_weights is not None:\n",
    "\t\t\tself.class_weights = torch.tensor(class_weights, dtype=torch.float).to(self.args.device)\n",
    "\t\telse:\n",
    "\t\t\tself.class_weights = None\n",
    "\n",
    "\tdef compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None, **kwargs):\n",
    "\t\tlabels = inputs.get(\"labels\")\n",
    "\t\toutputs = model(**inputs)\n",
    "\t\tlogits = outputs.get(\"logits\")\n",
    "\t\t\n",
    "\t\tif self.class_weights is not None:\n",
    "\t\t\tloss_fct = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "\t\t\tloss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "\t\telse:\n",
    "\t\t\t# Fallback to default loss if no weights are provided\n",
    "\t\t\tloss = outputs.loss if isinstance(outputs, dict) else outputs[0]\n",
    "\t\t\t\n",
    "\t\treturn (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\tlogits, labels = eval_pred\n",
    "\tpredictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "\tf1 = f1_score(labels, predictions, pos_label=1, average='binary')\n",
    "\treturn {\"f1_score_class_1\": f1}\n",
    "\n",
    "class_weights = [1.0, 9.0] # Weight class 0, weight class 1\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "\toutput_dir=\"./artifacts\",\n",
    "\tlearning_rate=2e-4,\n",
    "\tper_device_train_batch_size=2,\n",
    "\tgradient_accumulation_steps=16,\n",
    "\tnum_train_epochs=2,\n",
    "\tweight_decay=0.01,\n",
    "\tsave_strategy=\"steps\",\n",
    "\tsave_steps=50,\n",
    "\tsave_total_limit=3, \n",
    "\tload_best_model_at_end=True,\n",
    "\tmetric_for_best_model=\"f1_score_class_1\", \n",
    "\teval_strategy=\"steps\",\n",
    "\teval_steps=50,\n",
    "\tgreater_is_better=True,\n",
    "\tresume_from_checkpoint=False\n",
    ")\n",
    "\n",
    "\n",
    "path = \"./trained_model_ex3_f1_class1_weighted\"\n",
    "if (not os.path.exists(path) and RUN):\n",
    "\ttrainer = WeightedTrainer(\n",
    "\t\tmodel=model,\n",
    "\t\targs=training_args,\n",
    "\t\ttrain_dataset=tokenized_train_dataset,\n",
    "\t\teval_dataset=tokenized_eval_dataset,\n",
    "\t\tcompute_metrics=compute_metrics,\n",
    "\t\tclass_weights=class_weights,\n",
    "\t)\n",
    "\n",
    "\ttrainer.train(resume_from_checkpoint=True)\n",
    "\n",
    "\ttokenizer.save_pretrained(path)\n",
    "\ttrainer.save_model(path)\n",
    "else:\n",
    "\tprint(\"Model not trained\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3089f583",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9080e36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃    0.981    ┃  0.972   ┃   0.976    ┃   1871    ┃\n",
      "┃ 1  ┃    0.776    ┃  0.836   ┃   0.805    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.957    ┃  0.957   ┃   0.957    ┃\n",
      "┃ macro avg    ┃    0.878    ┃  0.904   ┃   0.891    ┃\n",
      "┃ weighted avg ┃    0.959    ┃  0.957   ┃   0.958    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "path = \"trained_model_ex3_precision_class1_v1\"\n",
    "if (os.path.exists(path)):\n",
    "\tmodel = AutoModelForSequenceClassification.from_pretrained(path, num_labels=2)\n",
    "\n",
    "\ttrainer = Trainer(model=model)\n",
    "\tpredictions_procentages = trainer.predict(tokenized_test_dataset)[0]\n",
    "\tpredictions = predictions_procentages.argmax(-1)\n",
    "\treport_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "\tpretty_print_report_dict(report_dict)\n",
    "else:\n",
    "\tprint(\"Model not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63650b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃    0.935    ┃  0.975   ┃   0.955    ┃   1871    ┃\n",
      "┃ 1  ┃    0.667    ┃  0.427   ┃   0.521    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.917    ┃  0.917   ┃   0.917    ┃\n",
      "┃ macro avg    ┃    0.801    ┃  0.701   ┃   0.738    ┃\n",
      "┃ weighted avg ┃    0.907    ┃  0.917   ┃   0.909    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "path = \"trained_model_ex3_v2_macro_f1_v1\"\n",
    "if (os.path.exists(path)):\n",
    "\tmodel = AutoModelForSequenceClassification.from_pretrained(path, num_labels=2)\n",
    "\n",
    "\ttrainer = Trainer(model=model)\n",
    "\tpredictions_procentages = trainer.predict(tokenized_test_dataset)[0]\n",
    "\tpredictions = predictions_procentages.argmax(-1)\n",
    "\treport_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "\tpretty_print_report_dict(report_dict)\n",
    "else:\n",
    "\tprint(\"Model not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4d7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃    0.981    ┃  0.975   ┃   0.978    ┃   1871    ┃\n",
      "┃ 1  ┃    0.797    ┃  0.836   ┃   0.816    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.96     ┃   0.96   ┃    0.96    ┃\n",
      "┃ macro avg    ┃    0.889    ┃  0.906   ┃   0.897    ┃\n",
      "┃ weighted avg ┃    0.961    ┃   0.96   ┃   0.961    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "path = \"trained_model_ex3_f1_class1_weighted\"\n",
    "if (os.path.exists(path)):\n",
    "\tmodel = AutoModelForSequenceClassification.from_pretrained(path, num_labels=2)\n",
    "\n",
    "\ttrainer = Trainer(model=model)\n",
    "\tpredictions_procentages = trainer.predict(tokenized_test_dataset)[0]\n",
    "\tpredictions = predictions_procentages.argmax(-1)\n",
    "\treport_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "\tpretty_print_report_dict(report_dict)\n",
    "else:\n",
    "\tprint(\"Model not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293bd42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃    0.982    ┃  0.974   ┃   0.978    ┃   1871    ┃\n",
      "┃ 1  ┃    0.791    ┃  0.845   ┃   0.818    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.96     ┃   0.96   ┃    0.96    ┃\n",
      "┃ macro avg    ┃    0.887    ┃   0.91   ┃   0.898    ┃\n",
      "┃ weighted avg ┃    0.962    ┃   0.96   ┃   0.961    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "path = \"trained_model_ex3_f1_class1_weighted_2_epoc\"\n",
    "if (os.path.exists(path)):\n",
    "\tmodel = AutoModelForSequenceClassification.from_pretrained(path, num_labels=2)\n",
    "\n",
    "\ttrainer = Trainer(model=model)\n",
    "\tpredictions_procentages = trainer.predict(tokenized_test_dataset)[0]\n",
    "\tpredictions = predictions_procentages.argmax(-1)\n",
    "\treport_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "\tpretty_print_report_dict(report_dict)\n",
    "else:\n",
    "\tprint(\"Model not found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec5edb7e",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ca1052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.losses import ContrastiveLoss, MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "\n",
    "# 3. Define the Hyperparameter Search Space\n",
    "def search_space(trial):\n",
    "    return {\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True),\n",
    "        'weight_decay': trial.suggest_float(\"weight_decay\", 0.01, 0.1),\n",
    "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.05, 0.2),\n",
    "        'max_grad_norm': trial.suggest_float(\"max_grad_norm\", 0.5, 1.0, log=True),\n",
    "        'num_train_epochs': trial.suggest_int(\"num_train_epochs\", 1, 10), # ! lower when using a slower model \n",
    "    }\n",
    "\n",
    "# 4. Define the Model Initialization\n",
    "def model_init(trial):\n",
    "    return SentenceTransformer(\"models\\jina-embeddings-v2-small-en\", device=\"cuda\" )\n",
    "\n",
    "# 5. Define the Loss Initialization\n",
    "def cl_loss_init(model):\n",
    "    return ContrastiveLoss(model)\n",
    "def mnlr_loss_init(model):\n",
    "    return MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# 6. Define the Objective Function\n",
    "def hpo_compute_objective(metrics):\n",
    "    print(metrics)\n",
    "    return metrics[\"eval_sts-dev_cosine_recall@10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4728a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "def get_data(valid_split=0.1):\n",
    "    train_data_path = \"./data/English dataset/train.jsonl\"\n",
    "    test_data_path = \"./data/English dataset/test.jsonl\"\n",
    "\n",
    "    train_data = pd.DataFrame(load_dataset(\"json\", data_files=train_data_path)[\"train\"])\n",
    "    test_dataset = pd.DataFrame(load_dataset(\"json\", data_files=test_data_path)[\"train\"])\n",
    "\n",
    "    label_map = {\"Contradiction\": 1, \"Entailment\": 0, \"NotMentioned\": 0}\n",
    "    train_data[\"label\"] = train_data[\"label\"].map(label_map)\n",
    "    test_dataset[\"label\"] = test_dataset[\"label\"].map(label_map)\n",
    "\n",
    "    train_data = train_data.drop(\"doc_id\", axis=1)\n",
    "    train_data = train_data.drop(\"key\", axis=1)\n",
    "    test_dataset = test_dataset.drop(\"doc_id\", axis=1)\n",
    "    test_dataset = test_dataset.drop(\"key\", axis=1)\n",
    "\n",
    "    train_data[\"label\"].value_counts(normalize=True)\n",
    "\n",
    "    ds = Dataset.from_pandas(train_data)\n",
    "    ds = ds.select_columns([\"hypothesis\", \"premise\", \"label\"])\n",
    "\n",
    "    dss = ds.train_test_split(valid_split, seed=42)\n",
    "    train_dataset = dss['train']\n",
    "    valid_dataset = dss['test']\n",
    "    test_dataset = Dataset.from_pandas(test_dataset)\n",
    "    test_dataset = test_dataset.select_columns([\"hypothesis\", \"premise\", \"label\"])\n",
    "\n",
    "    return train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "595a233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = get_data(valid_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d28c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_neg(data, model, params):\n",
    "    d = {'hypothesis':[], 'premise':[]}\n",
    "    for k in range(len(data)):\n",
    "        if data['label'][k] == 1:\n",
    "            d['hypothesis'].append(data['hypothesis'][k])\n",
    "            d['premise'].append(data['premise'][k])\n",
    "    meow = Dataset.from_dict(d)\n",
    "    return (meow, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e737aebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datasets import Dataset\n",
    "from datasets import Dataset\n",
    "from sentence_transformers.data_collator import SentenceTransformerDataCollator\n",
    "from torch._tensor import Tensor\n",
    "from typing import Any\n",
    "\n",
    "class MyDataCollator(SentenceTransformerDataCollator): # We need this so we can insert negatives to the batches\n",
    "    universal_negatives = ['', '']\n",
    "    negatives_per_batch = 4\n",
    "\n",
    "    def __call__(self, features: list[dict[str, Any]]) -> dict[str, Tensor]:\n",
    "        k = list(features[0].keys())[1]\n",
    "        for i, feature in enumerate(features):\n",
    "            features[i][k] = [features[i][k]] + random.sample(\n",
    "            self.universal_negatives, \n",
    "            min(self.negatives_per_batch, len(self.universal_negatives))\n",
    "        )\n",
    "        #print(features[i][k])\n",
    "        batch = super().__call__(features)\n",
    "        \n",
    "        return batch\n",
    "\n",
    "def get_data_col(data, model, params):\n",
    "    h = len(set(data['hypothesis']))\n",
    "    p = len(set(data['premise']))\n",
    "    \n",
    "    hmm = dict(zip(set(data['premise']), range(p)))\n",
    "    d = {'hypothesis':[], 'premise':[]}\n",
    "    for k in range(len(data)):\n",
    "        if data['label'][k] == 1:\n",
    "            d['hypothesis'].append(data['hypothesis'][k])\n",
    "            d['premise'].append(data['premise'][k])\n",
    "        else:\n",
    "            hmm[data['premise'][k]] += 1\n",
    "    universal_negatives = []\n",
    "    for k, v in hmm.items():\n",
    "        if v >= h: \n",
    "            universal_negatives.append(k) # if this premise is negative for all hypothesis\n",
    "    \n",
    "    data = Dataset.from_dict(d)\n",
    "    data_collator = MyDataCollator(model.tokenize)\n",
    "    data_collator.universal_negatives = universal_negatives\n",
    "    data_collator.negatives_per_batch = params['negatives_per_batch']\n",
    "\n",
    "    return data, data_collator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f50b9c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"models/checkpoints\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=1.2247359733257542e-05,\n",
    "    seed=42,\n",
    "    metric_for_best_model=f\"eval_cosine_recall@10\",\n",
    "    load_best_model_at_end=True,\n",
    "    weight_decay=0.09092585204374326,\n",
    "    warmup_ratio=0.05503071687326718,\n",
    "    batch_sampler=None,\n",
    "    #batch_sampler=BatchSamplers.NO_DUPLICATES,  # losses that use \"in-batch negatives\" benefit from no duplicates\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    torch_empty_cache_steps = None,\n",
    "    save_steps=50,\n",
    "    save_total_limit=2,\n",
    "    max_grad_norm= 0.8774817671930895,\n",
    "    logging_steps=100,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "49ac20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from copy import deepcopy\n",
    "\n",
    "args_mnlr = deepcopy(args)\n",
    "args_mnlr.num_train_epochs = 10\n",
    "args_mnlr.batch_sampler = BatchSamplers.NO_DUPLICATES\n",
    "args_mnlr2 = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"models/checkpoints\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=30,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=4.890585631921125e-05,\n",
    "    seed=42,\n",
    "    metric_for_best_model=f\"eval_cosine_recall@10\",\n",
    "    #load_best_model_at_end=True,\n",
    "    weight_decay=0.010800797401617856,\n",
    "    warmup_ratio=0.0765080638605733,\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # losses that use \"in-batch negatives\" benefit from no duplicates\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy=\"no\",\n",
    "    eval_steps=100,\n",
    "    torch_empty_cache_steps = None,\n",
    "    max_grad_norm= 0.5013390304609416,\n",
    "    logging_steps=100,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5029bed",
   "metadata": {},
   "source": [
    "MNLR assumes that in each batch every hypothesis has only one correct premise. It treates every other premise as a wrong answer, and tries to distance the hypothesis from it. This isn't true in general, so we need to ensure that during training, there aren't many overlaping premises. It's still possible that multiple correct premises for a hypothesis make it in the batch but NO_DUPLICATES tries to at least minimize that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "71a48263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import ContrastiveLoss, MultipleNegativesRankingLoss\n",
    "# Kinda bad, and slow but simple\n",
    "model_cl_kwargs = {\"trained_model_path\":\"models/trained/model_cl\", \"loss\": cl_loss_init, \"args\":args, \"model_init\":model_init}\n",
    "\n",
    "# kinda bad, but fast, and simple\n",
    "model_mnlr_kwargs = {\n",
    "    \"trained_model_path\":\"models/trained/model_mnlr\", \n",
    "    \"loss\":mnlr_loss_init, \n",
    "    \"args\":args_mnlr, \n",
    "    \"data_preprocesser\": filter_neg\n",
    "    }\n",
    "\n",
    "# our SOTA model\n",
    "model_mnlr2_kwargs = {\n",
    "    \"trained_model_path\":\"models/trained/model_mnlr2_test\", \n",
    "    \"loss\":mnlr_loss_init, \n",
    "    \"args\":args_mnlr2, \n",
    "    \"data_preprocesser\": get_data_col, \n",
    "    \"params\": {\"negatives_per_batch\":3},\n",
    "    \"model_init\":model_init\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5a7f0983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_ret_eval(test_dataset, name=''):\n",
    "    corpus = dict(zip(test_dataset['premise'], test_dataset['premise']))\n",
    "    queries = dict(zip(test_dataset['hypothesis'], test_dataset['hypothesis']))\n",
    "    relevant_docs = defaultdict(list)\n",
    "\n",
    "    for k in range(len(test_dataset)):\n",
    "        if test_dataset['label'][k] > 0:\n",
    "            relevant_docs[test_dataset['hypothesis'][k]].append(test_dataset['premise'][k])\n",
    "    \n",
    "\n",
    "    inf_ret_ev = InformationRetrievalEvaluator(\n",
    "        queries= queries,\n",
    "        corpus = corpus,\n",
    "        relevant_docs = relevant_docs,\n",
    "        #similarity_fn_names= [\"cosine\"],\n",
    "        show_progress_bar=True,\n",
    "        batch_size= 16,\n",
    "        #main_score_function=\"Recall@10\",\n",
    "        name=name\n",
    "    )\n",
    "\n",
    "    return inf_ret_ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c488a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import ContrastiveLoss\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "\n",
    "def get_trainer(\n",
    "        train_dataset, \n",
    "        valid_dataset, \n",
    "        model_init=model_init,\n",
    "        loss=mnlr_loss_init, \n",
    "        args=None, \n",
    "        evaluator=None, \n",
    "        data_preprocesser=None, \n",
    "        params=None,\n",
    "        trained_model_path=None,\n",
    "        early_stopping=False\n",
    "    ):\n",
    "    #base_model = SentenceTransformer(model_name)\n",
    "    \n",
    "    #loss = loss(base_model)\n",
    "    data_collator = None\n",
    "    if early_stopping:\n",
    "        early_stopper = [EarlyStoppingCallback(\n",
    "            early_stopping_patience=5,\n",
    "            early_stopping_threshold=0.05\n",
    "        )]\n",
    "    else:\n",
    "        early_stopper = None\n",
    "\n",
    "    if data_preprocesser is not None:\n",
    "        train_dataset, data_collator = data_preprocesser(train_dataset, model_init(None), params)\n",
    "\n",
    "    if valid_dataset is not None and evaluator is None:\n",
    "        evaluator = get_ret_eval(valid_dataset)\n",
    "\n",
    "    trainer = SentenceTransformerTrainer(\n",
    "        model_init = model_init,\n",
    "        train_dataset = train_dataset,\n",
    "        eval_dataset = valid_dataset,\n",
    "        loss = loss,\n",
    "        evaluator = evaluator,\n",
    "        args = args,\n",
    "        data_collator = data_collator,\n",
    "        callbacks=early_stopper\n",
    "    )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9938e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_search(train_dataset, valid_dataset, model_kwargs):\n",
    "    dev_evaluator = get_ret_eval(valid_dataset, name=\"sts-dev\")\n",
    "    model_kwargs = deepcopy(model_kwargs)\n",
    "    # 7. Define the training arguments\n",
    "    hpo_args = SentenceTransformerTrainingArguments(\n",
    "        # Required parameter:\n",
    "        num_train_epochs=1.0,\n",
    "        per_device_train_batch_size=16,\n",
    "        seed=42,\n",
    "        metric_for_best_model=f\"eval_cosine_recall@10\",\n",
    "        output_dir=\"checkpoints\",\n",
    "        batch_sampler=BatchSamplers.NO_DUPLICATES, # Remove if searching for the Contrastive loss or triplet model\n",
    "        # Optional tracking/debugging parameters:\n",
    "        eval_strategy=\"no\", # We don't need to evaluate/save during HPO\n",
    "        save_strategy=\"no\",\n",
    "        logging_steps=40,\n",
    "        run_name=\"hpo\",  # Will be used in W&B if `wandb` is installed\n",
    "        \n",
    "    )\n",
    "    model_kwargs['args'] = hpo_args\n",
    "    trainer = get_trainer(train_dataset, valid_dataset, evaluator=dev_evaluator, **model_kwargs)\n",
    "\n",
    "    best_trial = trainer.hyperparameter_search(\n",
    "        hp_space=search_space,\n",
    "        compute_objective=hpo_compute_objective,\n",
    "        n_trials=25,\n",
    "        direction=\"maximize\",\n",
    "        backend=\"optuna\",\n",
    "\n",
    "    )\n",
    "    print(best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "bca163fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataset, valid_dataset, model_kwargs):\n",
    "    trainer = get_trainer(train_dataset, valid_dataset,early_stopping=False, **model_kwargs)\n",
    "    trainer.train()\n",
    "    trainer.model.save_pretrained(model_kwargs['trained_model_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8fed48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True\n",
    "HYPER_PARAMETER_SEARCH = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a67226ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a27c3dbcb54dba9105ea5709ff5576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1380' max='1380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1380/1380 18:05, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.763700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.162300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.567900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.405700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.338800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.321600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.274100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.218300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.143500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.132500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.118300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    train(train_dataset, valid_dataset, model_mnlr2_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0040227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c2c50a97804f229aa068a7217c5a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 12:00:36,693] A new study created in memory with name: no-name-bfa4578b-9222-4053-aa49-01dc690d65bf\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:30, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.878400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7250' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [90/90 2:11:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2f3f50ced84879896dc76649f9a31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6cd3b0ee4484824aead8f0ab253c247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:04<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.458769291639328, 'eval_sts-dev_cosine_accuracy@1': 0.0, 'eval_sts-dev_cosine_accuracy@3': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@5': 0.4444444444444444, 'eval_sts-dev_cosine_accuracy@10': 0.5555555555555556, 'eval_sts-dev_cosine_precision@1': 0.0, 'eval_sts-dev_cosine_precision@3': 0.07407407407407407, 'eval_sts-dev_cosine_precision@5': 0.08888888888888889, 'eval_sts-dev_cosine_precision@10': 0.06666666666666667, 'eval_sts-dev_cosine_recall@1': 0.0, 'eval_sts-dev_cosine_recall@3': 0.012051734273956496, 'eval_sts-dev_cosine_recall@5': 0.1453850676072898, 'eval_sts-dev_cosine_recall@10': 0.1618685840908063, 'eval_sts-dev_cosine_ndcg@10': 0.10374839921798337, 'eval_sts-dev_cosine_mrr@10': 0.13994708994708993, 'eval_sts-dev_cosine_map@100': 0.05429728015926467, 'eval_runtime': 42.2138, 'eval_samples_per_second': 17.056, 'eval_steps_per_second': 2.132}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 12:01:53,100] Trial 0 finished with value: 0.1618685840908063 and parameters: {'learning_rate': 1.4059023675392549e-05, 'weight_decay': 0.08652978100312161, 'warmup_ratio': 0.056111534603025565, 'max_grad_norm': 0.7201799702327789, 'num_train_epochs': 1}. Best is trial 0 with value: 0.1618685840908063.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.924500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.745300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a9bb1cce5c46339f9882db5e286e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2961eaa56a16488c9922d3ed5a400589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4526253640651703, 'eval_sts-dev_cosine_accuracy@1': 0.0, 'eval_sts-dev_cosine_accuracy@3': 0.4444444444444444, 'eval_sts-dev_cosine_accuracy@5': 0.5555555555555556, 'eval_sts-dev_cosine_accuracy@10': 0.5555555555555556, 'eval_sts-dev_cosine_precision@1': 0.0, 'eval_sts-dev_cosine_precision@3': 0.14814814814814814, 'eval_sts-dev_cosine_precision@5': 0.1111111111111111, 'eval_sts-dev_cosine_precision@10': 0.08888888888888888, 'eval_sts-dev_cosine_recall@1': 0.0, 'eval_sts-dev_cosine_recall@3': 0.04282096504318727, 'eval_sts-dev_cosine_recall@5': 0.15393207615429835, 'eval_sts-dev_cosine_recall@10': 0.17453081897526337, 'eval_sts-dev_cosine_ndcg@10': 0.1347407111633424, 'eval_sts-dev_cosine_mrr@10': 0.21296296296296294, 'eval_sts-dev_cosine_map@100': 0.06724181459323575, 'eval_runtime': 28.71, 'eval_samples_per_second': 25.078, 'eval_steps_per_second': 3.135}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 12:03:30,629] Trial 1 finished with value: 0.17453081897526337 and parameters: {'learning_rate': 1.1307152640025565e-05, 'weight_decay': 0.03213871826104624, 'warmup_ratio': 0.18149397611707963, 'max_grad_norm': 0.886928100598736, 'num_train_epochs': 2}. Best is trial 1 with value: 0.17453081897526337.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='144' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [144/144 02:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.844800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.527600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.485200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56044004e0114983b42545d037287bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d0bea6cecd488eacef4d87e830ee93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:05<00:00,  5.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4388158619403839, 'eval_sts-dev_cosine_accuracy@1': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@3': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@5': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@10': 0.3333333333333333, 'eval_sts-dev_cosine_precision@1': 0.2222222222222222, 'eval_sts-dev_cosine_precision@3': 0.18518518518518517, 'eval_sts-dev_cosine_precision@5': 0.13333333333333336, 'eval_sts-dev_cosine_precision@10': 0.13333333333333333, 'eval_sts-dev_cosine_recall@1': 0.012051734273956496, 'eval_sts-dev_cosine_recall@3': 0.02821869488536155, 'eval_sts-dev_cosine_recall@5': 0.03233392122281011, 'eval_sts-dev_cosine_recall@10': 0.06527834305612083, 'eval_sts-dev_cosine_ndcg@10': 0.1458495452599458, 'eval_sts-dev_cosine_mrr@10': 0.23809523809523808, 'eval_sts-dev_cosine_map@100': 0.09419719689678425, 'eval_runtime': 54.1976, 'eval_samples_per_second': 13.285, 'eval_steps_per_second': 1.661}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 12:06:39,825] Trial 2 finished with value: 0.06527834305612083 and parameters: {'learning_rate': 3.305749542157708e-05, 'weight_decay': 0.03861318175267994, 'warmup_ratio': 0.09864380096271419, 'max_grad_norm': 0.8235775320157928, 'num_train_epochs': 3}. Best is trial 1 with value: 0.17453081897526337.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 07:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.954600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.695500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.553700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.377500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.217400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.065600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.762100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.727600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.749400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.568100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.597000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd527f73ce8540bd99dd5fb2768a78c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4851801e5d6f45fabd93daf6da3a3998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:10<00:00, 10.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46335354447364807, 'eval_sts-dev_cosine_accuracy@1': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@3': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@5': 0.4444444444444444, 'eval_sts-dev_cosine_accuracy@10': 0.4444444444444444, 'eval_sts-dev_cosine_precision@1': 0.2222222222222222, 'eval_sts-dev_cosine_precision@3': 0.2222222222222222, 'eval_sts-dev_cosine_precision@5': 0.17777777777777776, 'eval_sts-dev_cosine_precision@10': 0.15555555555555556, 'eval_sts-dev_cosine_recall@1': 0.012051734273956496, 'eval_sts-dev_cosine_recall@3': 0.05044091710758378, 'eval_sts-dev_cosine_recall@5': 0.16566725455614342, 'eval_sts-dev_cosine_recall@10': 0.19800117577895354, 'eval_sts-dev_cosine_ndcg@10': 0.21564108349937677, 'eval_sts-dev_cosine_mrr@10': 0.30000000000000004, 'eval_sts-dev_cosine_map@100': 0.17312402206760572, 'eval_runtime': 60.7544, 'eval_samples_per_second': 11.851, 'eval_steps_per_second': 1.481}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 12:15:23,345] Trial 3 finished with value: 0.19800117577895354 and parameters: {'learning_rate': 2.4008763114912577e-05, 'weight_decay': 0.0639786658560054, 'warmup_ratio': 0.13520976901078668, 'max_grad_norm': 0.9083848011763486, 'num_train_epochs': 10}. Best is trial 3 with value: 0.19800117577895354.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 02:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.917700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.628900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.517000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.340500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.250300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.053400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf0a52da1d54a49b6acf440c82e2a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512a80b576fc4093acc0de41a1bf948a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:03<00:00,  3.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4271654188632965, 'eval_sts-dev_cosine_accuracy@1': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@3': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@5': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@10': 0.4444444444444444, 'eval_sts-dev_cosine_precision@1': 0.2222222222222222, 'eval_sts-dev_cosine_precision@3': 0.14814814814814814, 'eval_sts-dev_cosine_precision@5': 0.1111111111111111, 'eval_sts-dev_cosine_precision@10': 0.14444444444444446, 'eval_sts-dev_cosine_recall@1': 0.012051734273956496, 'eval_sts-dev_cosine_recall@3': 0.03838918283362728, 'eval_sts-dev_cosine_recall@5': 0.046325690770135215, 'eval_sts-dev_cosine_recall@10': 0.09132184687740244, 'eval_sts-dev_cosine_ndcg@10': 0.15565542226436846, 'eval_sts-dev_cosine_mrr@10': 0.27037037037037037, 'eval_sts-dev_cosine_map@100': 0.10618913599860787, 'eval_runtime': 26.3252, 'eval_samples_per_second': 27.35, 'eval_steps_per_second': 3.419}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 12:18:29,231] Trial 4 finished with value: 0.09132184687740244 and parameters: {'learning_rate': 2.5231364409635767e-05, 'weight_decay': 0.02873923782471332, 'warmup_ratio': 0.17544082335077604, 'max_grad_norm': 0.7311139395028325, 'num_train_epochs': 5}. Best is trial 3 with value: 0.19800117577895354.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 02:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.827500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.467500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.385200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.097200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.794600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be92a62b2362492791ef4bfe19538eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b301dc8a744dc5b5565eea31125115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:03<00:00,  3.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4230436384677887, 'eval_sts-dev_cosine_accuracy@1': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@3': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@5': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@10': 0.4444444444444444, 'eval_sts-dev_cosine_precision@1': 0.3333333333333333, 'eval_sts-dev_cosine_precision@3': 0.2222222222222222, 'eval_sts-dev_cosine_precision@5': 0.24444444444444446, 'eval_sts-dev_cosine_precision@10': 0.1888888888888889, 'eval_sts-dev_cosine_recall@1': 0.020598742820965042, 'eval_sts-dev_cosine_recall@3': 0.036765703432370095, 'eval_sts-dev_cosine_recall@5': 0.07384796273685162, 'eval_sts-dev_cosine_recall@10': 0.12107809885587664, 'eval_sts-dev_cosine_ndcg@10': 0.21224070030521797, 'eval_sts-dev_cosine_mrr@10': 0.34444444444444444, 'eval_sts-dev_cosine_map@100': 0.15282343537855797, 'eval_runtime': 26.5233, 'eval_samples_per_second': 27.146, 'eval_steps_per_second': 3.393}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 12:21:43,519] Trial 5 finished with value: 0.12107809885587664 and parameters: {'learning_rate': 3.881667226159113e-05, 'weight_decay': 0.05515720194350113, 'warmup_ratio': 0.0556556309422569, 'max_grad_norm': 0.5290798862185233, 'num_train_epochs': 5}. Best is trial 3 with value: 0.19800117577895354.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 02:43, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.742100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.685400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.618300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.405000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb2ae5b66ae4e56b9cacbbe2375c6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142e6043801e4f9998ac701c09427ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:03<00:00,  3.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4461458921432495, 'eval_sts-dev_cosine_accuracy@1': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@3': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@5': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@10': 0.5555555555555556, 'eval_sts-dev_cosine_precision@1': 0.2222222222222222, 'eval_sts-dev_cosine_precision@3': 0.1111111111111111, 'eval_sts-dev_cosine_precision@5': 0.1111111111111111, 'eval_sts-dev_cosine_precision@10': 0.13333333333333333, 'eval_sts-dev_cosine_recall@1': 0.012051734273956496, 'eval_sts-dev_cosine_recall@3': 0.016166960611405056, 'eval_sts-dev_cosine_recall@5': 0.024397413286302173, 'eval_sts-dev_cosine_recall@10': 0.18655994211549765, 'eval_sts-dev_cosine_ndcg@10': 0.1724591662635654, 'eval_sts-dev_cosine_mrr@10': 0.2669753086419753, 'eval_sts-dev_cosine_map@100': 0.08920091005029075, 'eval_runtime': 26.002, 'eval_samples_per_second': 27.69, 'eval_steps_per_second': 3.461}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 12:24:55,704] Trial 6 finished with value: 0.18655994211549765 and parameters: {'learning_rate': 1.0620933794507456e-05, 'weight_decay': 0.03635588704482753, 'warmup_ratio': 0.12884989894318657, 'max_grad_norm': 0.7598787704170058, 'num_train_epochs': 5}. Best is trial 3 with value: 0.19800117577895354.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 05:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.950200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.684900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.497100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.267100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.067900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.804400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.796900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.623200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.535400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.601100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.474500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.412200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a49ec43418d4b3c81788d08cb37be71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873bb86b09444bcf9ca702cb6d1412a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:03<00:00,  3.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.48427870869636536, 'eval_sts-dev_cosine_accuracy@1': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@3': 0.4444444444444444, 'eval_sts-dev_cosine_accuracy@5': 0.4444444444444444, 'eval_sts-dev_cosine_accuracy@10': 0.4444444444444444, 'eval_sts-dev_cosine_precision@1': 0.3333333333333333, 'eval_sts-dev_cosine_precision@3': 0.25925925925925924, 'eval_sts-dev_cosine_precision@5': 0.2222222222222222, 'eval_sts-dev_cosine_precision@10': 0.14444444444444446, 'eval_sts-dev_cosine_recall@1': 0.020598742820965042, 'eval_sts-dev_cosine_recall@3': 0.059598426265092944, 'eval_sts-dev_cosine_recall@5': 0.07576538687649798, 'eval_sts-dev_cosine_recall@10': 0.1100393433726767, 'eval_sts-dev_cosine_ndcg@10': 0.19206181648008988, 'eval_sts-dev_cosine_mrr@10': 0.3703703703703704, 'eval_sts-dev_cosine_map@100': 0.17846353900861278, 'eval_runtime': 27.2704, 'eval_samples_per_second': 26.402, 'eval_steps_per_second': 3.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 12:30:43,679] Trial 7 finished with value: 0.1100393433726767 and parameters: {'learning_rate': 3.524440852268008e-05, 'weight_decay': 0.08347971655397256, 'warmup_ratio': 0.18411295981410541, 'max_grad_norm': 0.5454412406726281, 'num_train_epochs': 10}. Best is trial 3 with value: 0.19800117577895354.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='336' max='336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [336/336 04:27, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.869400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.534600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.363300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.165300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.969400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.708000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.731800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.575900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba0ef5487274e0b9464326f05a98ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba3a14bd0b542ab962e2b8fbfcecf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:07<00:00,  7.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44954603910446167, 'eval_sts-dev_cosine_accuracy@1': 0.1111111111111111, 'eval_sts-dev_cosine_accuracy@3': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@5': 0.4444444444444444, 'eval_sts-dev_cosine_accuracy@10': 0.5555555555555556, 'eval_sts-dev_cosine_precision@1': 0.1111111111111111, 'eval_sts-dev_cosine_precision@3': 0.18518518518518517, 'eval_sts-dev_cosine_precision@5': 0.20000000000000004, 'eval_sts-dev_cosine_precision@10': 0.17777777777777778, 'eval_sts-dev_cosine_recall@1': 0.004115226337448559, 'eval_sts-dev_cosine_recall@3': 0.03265047709492154, 'eval_sts-dev_cosine_recall@5': 0.16053904942793829, 'eval_sts-dev_cosine_recall@10': 0.23381268936824492, 'eval_sts-dev_cosine_ndcg@10': 0.2136758139143756, 'eval_sts-dev_cosine_mrr@10': 0.2444444444444444, 'eval_sts-dev_cosine_map@100': 0.16171511441995806, 'eval_runtime': 44.9039, 'eval_samples_per_second': 16.034, 'eval_steps_per_second': 2.004}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 12:35:58,631] Trial 8 finished with value: 0.23381268936824492 and parameters: {'learning_rate': 4.481427220776346e-05, 'weight_decay': 0.018681887598305823, 'warmup_ratio': 0.10699351633723574, 'max_grad_norm': 0.5582517475197748, 'num_train_epochs': 7}. Best is trial 8 with value: 0.23381268936824492.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 05:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.882700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.564200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.393800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.170900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.913800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.694100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.690900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.538500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.496500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.394200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e1314dff5746a4b1ea96b5f218a569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21ef7b1e134450fb42d4c288db9c063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:04<00:00,  4.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46136242151260376, 'eval_sts-dev_cosine_accuracy@1': 0.1111111111111111, 'eval_sts-dev_cosine_accuracy@3': 0.4444444444444444, 'eval_sts-dev_cosine_accuracy@5': 0.4444444444444444, 'eval_sts-dev_cosine_accuracy@10': 0.4444444444444444, 'eval_sts-dev_cosine_precision@1': 0.1111111111111111, 'eval_sts-dev_cosine_precision@3': 0.2592592592592593, 'eval_sts-dev_cosine_precision@5': 0.2222222222222222, 'eval_sts-dev_cosine_precision@10': 0.20000000000000004, 'eval_sts-dev_cosine_recall@1': 0.004115226337448559, 'eval_sts-dev_cosine_recall@3': 0.05898792565459232, 'eval_sts-dev_cosine_recall@5': 0.07576538687649798, 'eval_sts-dev_cosine_recall@10': 0.12901460679238458, 'eval_sts-dev_cosine_ndcg@10': 0.20837158948889034, 'eval_sts-dev_cosine_mrr@10': 0.25925925925925924, 'eval_sts-dev_cosine_map@100': 0.17943237040210175, 'eval_runtime': 31.076, 'eval_samples_per_second': 23.169, 'eval_steps_per_second': 2.896}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 12:42:31,368] Trial 9 finished with value: 0.12901460679238458 and parameters: {'learning_rate': 4.44362668830459e-05, 'weight_decay': 0.07644873292094105, 'warmup_ratio': 0.08770045454444267, 'max_grad_norm': 0.7461189353702702, 'num_train_epochs': 10}. Best is trial 8 with value: 0.23381268936824492.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 05:26, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.975200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.734500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.637800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.514000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.410200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.220300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.330100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.219100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.204000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24a54ec09a740b1b731b56fa56bec1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8d8faa7672407082a1eff303ed93cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:12<00:00, 12.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.423377126455307, 'eval_sts-dev_cosine_accuracy@1': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@3': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@5': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@10': 0.4444444444444444, 'eval_sts-dev_cosine_precision@1': 0.2222222222222222, 'eval_sts-dev_cosine_precision@3': 0.18518518518518517, 'eval_sts-dev_cosine_precision@5': 0.17777777777777776, 'eval_sts-dev_cosine_precision@10': 0.15555555555555556, 'eval_sts-dev_cosine_recall@1': 0.012051734273956496, 'eval_sts-dev_cosine_recall@3': 0.042504409171075834, 'eval_sts-dev_cosine_recall@5': 0.0586713697824809, 'eval_sts-dev_cosine_recall@10': 0.0960475738253516, 'eval_sts-dev_cosine_ndcg@10': 0.16929536599952635, 'eval_sts-dev_cosine_mrr@10': 0.271604938271605, 'eval_sts-dev_cosine_map@100': 0.12717345594367999, 'eval_runtime': 69.5385, 'eval_samples_per_second': 10.354, 'eval_steps_per_second': 1.294}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 12:49:09,289] Trial 10 finished with value: 0.0960475738253516 and parameters: {'learning_rate': 1.6009592922779148e-05, 'weight_decay': 0.013124712974743321, 'warmup_ratio': 0.1531321794002561, 'max_grad_norm': 0.6015599074781625, 'num_train_epochs': 8}. Best is trial 8 with value: 0.23381268936824492.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 05:23, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.942700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.680400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.558400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.427400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.303500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.065700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.160300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.037600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.008100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2cf0c7e67749e8a68f7d2dbaa369c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c89406dbc6e495b85670a71f0b62a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:12<00:00, 12.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41803425550460815, 'eval_sts-dev_cosine_accuracy@1': 0.1111111111111111, 'eval_sts-dev_cosine_accuracy@3': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@5': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@10': 0.5555555555555556, 'eval_sts-dev_cosine_precision@1': 0.1111111111111111, 'eval_sts-dev_cosine_precision@3': 0.1111111111111111, 'eval_sts-dev_cosine_precision@5': 0.15555555555555556, 'eval_sts-dev_cosine_precision@10': 0.15555555555555556, 'eval_sts-dev_cosine_recall@1': 0.004115226337448559, 'eval_sts-dev_cosine_recall@3': 0.03427395649617872, 'eval_sts-dev_cosine_recall@5': 0.07648442092886537, 'eval_sts-dev_cosine_recall@10': 0.2211504544837878, 'eval_sts-dev_cosine_ndcg@10': 0.18746048675771756, 'eval_sts-dev_cosine_mrr@10': 0.2361111111111111, 'eval_sts-dev_cosine_map@100': 0.12564987518767798, 'eval_runtime': 63.8752, 'eval_samples_per_second': 11.272, 'eval_steps_per_second': 1.409}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 12:55:39,072] Trial 11 finished with value: 0.2211504544837878 and parameters: {'learning_rate': 2.119476921266994e-05, 'weight_decay': 0.06241016459553604, 'warmup_ratio': 0.12387983002574698, 'max_grad_norm': 0.9612691535017999, 'num_train_epochs': 8}. Best is trial 8 with value: 0.23381268936824492.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='336' max='336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [336/336 04:14, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.925100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.670600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.551500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.449400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.346700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.164500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.287600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.201000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3207d7e9d474572a23d60fa6c56dac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833f8260e53043e8ac98c6a9fdf98505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:07<00:00,  7.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43358680605888367, 'eval_sts-dev_cosine_accuracy@1': 0.1111111111111111, 'eval_sts-dev_cosine_accuracy@3': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@5': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@10': 0.5555555555555556, 'eval_sts-dev_cosine_precision@1': 0.1111111111111111, 'eval_sts-dev_cosine_precision@3': 0.14814814814814814, 'eval_sts-dev_cosine_precision@5': 0.1111111111111111, 'eval_sts-dev_cosine_precision@10': 0.16666666666666663, 'eval_sts-dev_cosine_recall@1': 0.007936507936507936, 'eval_sts-dev_cosine_recall@3': 0.12727807172251615, 'eval_sts-dev_cosine_recall@5': 0.13139329805996472, 'eval_sts-dev_cosine_recall@10': 0.22465518021073574, 'eval_sts-dev_cosine_ndcg@10': 0.20502840413067921, 'eval_sts-dev_cosine_mrr@10': 0.23809523809523808, 'eval_sts-dev_cosine_map@100': 0.15311991867035382, 'eval_runtime': 39.6906, 'eval_samples_per_second': 18.14, 'eval_steps_per_second': 2.268}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 13:00:35,548] Trial 12 finished with value: 0.22465518021073574 and parameters: {'learning_rate': 1.8240995963110922e-05, 'weight_decay': 0.09874664134664762, 'warmup_ratio': 0.0999724069653248, 'max_grad_norm': 0.6325094738820446, 'num_train_epochs': 7}. Best is trial 8 with value: 0.23381268936824492.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='336' max='336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [336/336 04:44, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.921400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.660400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.535600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.425200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.338400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.294000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.186400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efcd46530114a9e8f04c7b3607d6c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a35382d787046ef94de20c45c0a0879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:05<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4368283152580261, 'eval_sts-dev_cosine_accuracy@1': 0.1111111111111111, 'eval_sts-dev_cosine_accuracy@3': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@5': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@10': 0.5555555555555556, 'eval_sts-dev_cosine_precision@1': 0.1111111111111111, 'eval_sts-dev_cosine_precision@3': 0.1111111111111111, 'eval_sts-dev_cosine_precision@5': 0.1111111111111111, 'eval_sts-dev_cosine_precision@10': 0.16666666666666666, 'eval_sts-dev_cosine_recall@1': 0.004115226337448559, 'eval_sts-dev_cosine_recall@3': 0.016166960611405056, 'eval_sts-dev_cosine_recall@5': 0.03203997648442093, 'eval_sts-dev_cosine_recall@10': 0.21036946592502148, 'eval_sts-dev_cosine_ndcg@10': 0.18971109549742082, 'eval_sts-dev_cosine_mrr@10': 0.21494708994708991, 'eval_sts-dev_cosine_map@100': 0.13166637096223963, 'eval_runtime': 35.6228, 'eval_samples_per_second': 20.212, 'eval_steps_per_second': 2.526}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 13:05:58,531] Trial 13 finished with value: 0.21036946592502148 and parameters: {'learning_rate': 1.8213748517391996e-05, 'weight_decay': 0.09911914992277315, 'warmup_ratio': 0.09416079657814064, 'max_grad_norm': 0.6185226223920901, 'num_train_epochs': 7}. Best is trial 8 with value: 0.23381268936824492.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='336' max='336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [336/336 04:14, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.894800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.593200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.489300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.258500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.111400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.867600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.988500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c099af6be740a3abd30650ccf5e3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2adba277da41d1ac260728411aa407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:06<00:00,  6.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40545687079429626, 'eval_sts-dev_cosine_accuracy@1': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@3': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@5': 0.4444444444444444, 'eval_sts-dev_cosine_accuracy@10': 0.4444444444444444, 'eval_sts-dev_cosine_precision@1': 0.3333333333333333, 'eval_sts-dev_cosine_precision@3': 0.2222222222222222, 'eval_sts-dev_cosine_precision@5': 0.2, 'eval_sts-dev_cosine_precision@10': 0.17777777777777776, 'eval_sts-dev_cosine_recall@1': 0.03427395649617872, 'eval_sts-dev_cosine_recall@3': 0.05044091710758378, 'eval_sts-dev_cosine_recall@5': 0.17360376249265136, 'eval_sts-dev_cosine_recall@10': 0.2281599059376837, 'eval_sts-dev_cosine_ndcg@10': 0.25580872808689054, 'eval_sts-dev_cosine_mrr@10': 0.3611111111111111, 'eval_sts-dev_cosine_map@100': 0.19412605809565242, 'eval_runtime': 38.0251, 'eval_samples_per_second': 18.935, 'eval_steps_per_second': 2.367}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 13:10:53,557] Trial 14 finished with value: 0.2281599059376837 and parameters: {'learning_rate': 2.957310669752699e-05, 'weight_decay': 0.017492853519975777, 'warmup_ratio': 0.10854236410882438, 'max_grad_norm': 0.6356174549758085, 'num_train_epochs': 7}. Best is trial 8 with value: 0.23381268936824492.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='336' max='336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [336/336 04:32, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.835100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.419400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.927300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.711600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.542800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.622800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.522100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002df2f57e07491eb785577c850365e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0d0a8fd91f426fbedafa84dc860ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:04<00:00,  4.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4794270098209381, 'eval_sts-dev_cosine_accuracy@1': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@3': 0.4444444444444444, 'eval_sts-dev_cosine_accuracy@5': 0.5555555555555556, 'eval_sts-dev_cosine_accuracy@10': 0.5555555555555556, 'eval_sts-dev_cosine_precision@1': 0.2222222222222222, 'eval_sts-dev_cosine_precision@3': 0.2592592592592593, 'eval_sts-dev_cosine_precision@5': 0.2666666666666667, 'eval_sts-dev_cosine_precision@10': 0.21111111111111114, 'eval_sts-dev_cosine_recall@1': 0.02633744855967078, 'eval_sts-dev_cosine_recall@3': 0.05898792565459232, 'eval_sts-dev_cosine_recall@5': 0.194813005924117, 'eval_sts-dev_cosine_recall@10': 0.27251842807398363, 'eval_sts-dev_cosine_ndcg@10': 0.28315354091008627, 'eval_sts-dev_cosine_mrr@10': 0.3611111111111111, 'eval_sts-dev_cosine_map@100': 0.20286949962284767, 'eval_runtime': 30.5611, 'eval_samples_per_second': 23.559, 'eval_steps_per_second': 2.945}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 13:15:58,692] Trial 15 finished with value: 0.27251842807398363 and parameters: {'learning_rate': 4.890585631921125e-05, 'weight_decay': 0.010800797401617856, 'warmup_ratio': 0.0765080638605733, 'max_grad_norm': 0.5013390304609416, 'num_train_epochs': 7}. Best is trial 15 with value: 0.27251842807398363.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [288/288 03:22, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.836400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.301200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.762200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.626000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.733000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20d44aa8f604cfeb8103f6d12a87b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b7bd3ca4b444ac9d95cf30d90f3538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:04<00:00,  4.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4111362397670746, 'eval_sts-dev_cosine_accuracy@1': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@3': 0.4444444444444444, 'eval_sts-dev_cosine_accuracy@5': 0.4444444444444444, 'eval_sts-dev_cosine_accuracy@10': 0.4444444444444444, 'eval_sts-dev_cosine_precision@1': 0.2222222222222222, 'eval_sts-dev_cosine_precision@3': 0.2592592592592593, 'eval_sts-dev_cosine_precision@5': 0.2, 'eval_sts-dev_cosine_precision@10': 0.17777777777777776, 'eval_sts-dev_cosine_recall@1': 0.012662234884457106, 'eval_sts-dev_cosine_recall@3': 0.1484873151539818, 'eval_sts-dev_cosine_recall@5': 0.16114955003843892, 'eval_sts-dev_cosine_recall@10': 0.20646226201781756, 'eval_sts-dev_cosine_ndcg@10': 0.25246467392391536, 'eval_sts-dev_cosine_mrr@10': 0.31481481481481477, 'eval_sts-dev_cosine_map@100': 0.21046999000919103, 'eval_runtime': 29.3319, 'eval_samples_per_second': 24.547, 'eval_steps_per_second': 3.068}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 13:19:52,214] Trial 16 finished with value: 0.20646226201781756 and parameters: {'learning_rate': 4.714612267183037e-05, 'weight_decay': 0.021105657644510604, 'warmup_ratio': 0.07411727571172634, 'max_grad_norm': 0.5003133766692207, 'num_train_epochs': 6}. Best is trial 15 with value: 0.27251842807398363.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/192 03:04, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.815900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.422900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.231100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.969500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078f0cfd688544fc9c251656db36a29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4b286cdae4481db422db6949e00f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41396859288215637, 'eval_sts-dev_cosine_accuracy@1': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@3': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@5': 0.4444444444444444, 'eval_sts-dev_cosine_accuracy@10': 0.4444444444444444, 'eval_sts-dev_cosine_precision@1': 0.2222222222222222, 'eval_sts-dev_cosine_precision@3': 0.2222222222222222, 'eval_sts-dev_cosine_precision@5': 0.24444444444444446, 'eval_sts-dev_cosine_precision@10': 0.18888888888888888, 'eval_sts-dev_cosine_recall@1': 0.012051734273956496, 'eval_sts-dev_cosine_recall@3': 0.05044091710758378, 'eval_sts-dev_cosine_recall@5': 0.0830913942025053, 'eval_sts-dev_cosine_recall@10': 0.13475331253109032, 'eval_sts-dev_cosine_ndcg@10': 0.21436115424660712, 'eval_sts-dev_cosine_mrr@10': 0.30000000000000004, 'eval_sts-dev_cosine_map@100': 0.15402947916523368, 'eval_runtime': 37.6509, 'eval_samples_per_second': 19.123, 'eval_steps_per_second': 2.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 13:23:36,548] Trial 17 finished with value: 0.13475331253109032 and parameters: {'learning_rate': 4.819804776100613e-05, 'weight_decay': 0.011193435549142865, 'warmup_ratio': 0.07430928210629331, 'max_grad_norm': 0.5473684287520074, 'num_train_epochs': 4}. Best is trial 15 with value: 0.27251842807398363.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 05:16, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.866600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.520300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.421000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.162000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.961100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.706000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.770800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.522700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.502700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c403940ce11241339ac7833167ca9076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449b1d35201c495fa6a7e2e90725bb4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:06<00:00,  6.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.445940226316452, 'eval_sts-dev_cosine_accuracy@1': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@3': 0.4444444444444444, 'eval_sts-dev_cosine_accuracy@5': 0.5555555555555556, 'eval_sts-dev_cosine_accuracy@10': 0.6666666666666666, 'eval_sts-dev_cosine_precision@1': 0.2222222222222222, 'eval_sts-dev_cosine_precision@3': 0.25925925925925924, 'eval_sts-dev_cosine_precision@5': 0.22222222222222227, 'eval_sts-dev_cosine_precision@10': 0.2, 'eval_sts-dev_cosine_recall@1': 0.012051734273956496, 'eval_sts-dev_cosine_recall@3': 0.1478768145434812, 'eval_sts-dev_cosine_recall@5': 0.1821507710396599, 'eval_sts-dev_cosine_recall@10': 0.2458644236422014, 'eval_sts-dev_cosine_ndcg@10': 0.26340519645847693, 'eval_sts-dev_cosine_mrr@10': 0.3611111111111111, 'eval_sts-dev_cosine_map@100': 0.1985251904435118, 'eval_runtime': 39.3006, 'eval_samples_per_second': 18.32, 'eval_steps_per_second': 2.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 13:29:34,398] Trial 18 finished with value: 0.2458644236422014 and parameters: {'learning_rate': 3.903330335485093e-05, 'weight_decay': 0.044324840264284585, 'warmup_ratio': 0.0737898083064729, 'max_grad_norm': 0.5814222614025382, 'num_train_epochs': 8}. Best is trial 15 with value: 0.27251842807398363.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='432' max='432' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [432/432 07:47, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.874100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.536100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.357300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.105400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.898000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.642300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.664900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.554000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.447100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.567600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd60fe4e800e40f08697e1658eadf5b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0b4d8c5c444fc186be1b17ae6a52a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:18<00:00, 18.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.53395676612854, 'eval_sts-dev_cosine_accuracy@1': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@3': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@5': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@10': 0.5555555555555556, 'eval_sts-dev_cosine_precision@1': 0.2222222222222222, 'eval_sts-dev_cosine_precision@3': 0.2222222222222222, 'eval_sts-dev_cosine_precision@5': 0.17777777777777776, 'eval_sts-dev_cosine_precision@10': 0.18888888888888888, 'eval_sts-dev_cosine_recall@1': 0.012051734273956496, 'eval_sts-dev_cosine_recall@3': 0.05044091710758378, 'eval_sts-dev_cosine_recall@5': 0.0586713697824809, 'eval_sts-dev_cosine_recall@10': 0.23731741509519283, 'eval_sts-dev_cosine_ndcg@10': 0.23041291580965229, 'eval_sts-dev_cosine_mrr@10': 0.3027777777777778, 'eval_sts-dev_cosine_map@100': 0.1648766473559311, 'eval_runtime': 69.3921, 'eval_samples_per_second': 10.376, 'eval_steps_per_second': 1.297}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 13:38:33,528] Trial 19 finished with value: 0.23731741509519283 and parameters: {'learning_rate': 3.793025413027487e-05, 'weight_decay': 0.04473207350417616, 'warmup_ratio': 0.07326011861969792, 'max_grad_norm': 0.6689413499652381, 'num_train_epochs': 9}. Best is trial 15 with value: 0.27251842807398363.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='432' max='432' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [432/432 07:22, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.874900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.578900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.446800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.263100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.852600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.909600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.698000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.731000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.679800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8599dce54741008ae070c9aa4af126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c97668cbfe4ad7a471313b9bae1930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:10<00:00, 10.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4347043037414551, 'eval_sts-dev_cosine_accuracy@1': 0.1111111111111111, 'eval_sts-dev_cosine_accuracy@3': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@5': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@10': 0.5555555555555556, 'eval_sts-dev_cosine_precision@1': 0.1111111111111111, 'eval_sts-dev_cosine_precision@3': 0.18518518518518517, 'eval_sts-dev_cosine_precision@5': 0.17777777777777776, 'eval_sts-dev_cosine_precision@10': 0.2, 'eval_sts-dev_cosine_recall@1': 0.004115226337448559, 'eval_sts-dev_cosine_recall@3': 0.042504409171075834, 'eval_sts-dev_cosine_recall@5': 0.06249265138154028, 'eval_sts-dev_cosine_recall@10': 0.24968570524126082, 'eval_sts-dev_cosine_ndcg@10': 0.23623685948103837, 'eval_sts-dev_cosine_mrr@10': 0.25661375661375657, 'eval_sts-dev_cosine_map@100': 0.1683845085375392, 'eval_runtime': 65.8867, 'eval_samples_per_second': 10.928, 'eval_steps_per_second': 1.366}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 13:47:05,819] Trial 20 finished with value: 0.24968570524126082 and parameters: {'learning_rate': 2.8068401086894654e-05, 'weight_decay': 0.04698765510395305, 'warmup_ratio': 0.05124379716477055, 'max_grad_norm': 0.5009236516133213, 'num_train_epochs': 9}. Best is trial 15 with value: 0.27251842807398363.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='432' max='432' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [432/432 06:15, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.869300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.436600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.175100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.034100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.815600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.872000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.603900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.601100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.604400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a63c21c7374ca09e407a8339e31b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f727047f8eb43e196e37e47c6489b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:10<00:00, 10.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4603928029537201, 'eval_sts-dev_cosine_accuracy@1': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@3': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@5': 0.4444444444444444, 'eval_sts-dev_cosine_accuracy@10': 0.5555555555555556, 'eval_sts-dev_cosine_precision@1': 0.3333333333333333, 'eval_sts-dev_cosine_precision@3': 0.18518518518518517, 'eval_sts-dev_cosine_precision@5': 0.2, 'eval_sts-dev_cosine_precision@10': 0.18888888888888888, 'eval_sts-dev_cosine_recall@1': 0.03427395649617872, 'eval_sts-dev_cosine_recall@3': 0.042504409171075834, 'eval_sts-dev_cosine_recall@5': 0.06721837832948944, 'eval_sts-dev_cosine_recall@10': 0.24113869669425225, 'eval_sts-dev_cosine_ndcg@10': 0.24934925457204096, 'eval_sts-dev_cosine_mrr@10': 0.3714285714285714, 'eval_sts-dev_cosine_map@100': 0.1783763748008684, 'eval_runtime': 62.1964, 'eval_samples_per_second': 11.576, 'eval_steps_per_second': 1.447}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 13:54:26,937] Trial 21 finished with value: 0.24113869669425225 and parameters: {'learning_rate': 2.9172756085030926e-05, 'weight_decay': 0.04855095567449332, 'warmup_ratio': 0.05016085581775753, 'max_grad_norm': 0.5018701496819169, 'num_train_epochs': 9}. Best is trial 15 with value: 0.27251842807398363.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/384 05:17, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.877800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.573100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.423100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.862300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.939100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.714700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.753700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee39d7823c984fbe9c02e946845fe299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37925058501f4f14bec3a2b4816978bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:09<00:00,  9.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.425436794757843, 'eval_sts-dev_cosine_accuracy@1': 0.1111111111111111, 'eval_sts-dev_cosine_accuracy@3': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@5': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@10': 0.6666666666666666, 'eval_sts-dev_cosine_precision@1': 0.1111111111111111, 'eval_sts-dev_cosine_precision@3': 0.18518518518518517, 'eval_sts-dev_cosine_precision@5': 0.17777777777777776, 'eval_sts-dev_cosine_precision@10': 0.17777777777777778, 'eval_sts-dev_cosine_recall@1': 0.004115226337448559, 'eval_sts-dev_cosine_recall@3': 0.046325690770135215, 'eval_sts-dev_cosine_recall@5': 0.06249265138154028, 'eval_sts-dev_cosine_recall@10': 0.21952697508253063, 'eval_sts-dev_cosine_ndcg@10': 0.20704628482999607, 'eval_sts-dev_cosine_mrr@10': 0.26432980599647266, 'eval_sts-dev_cosine_map@100': 0.15307262796557874, 'eval_runtime': 49.0083, 'eval_samples_per_second': 14.691, 'eval_steps_per_second': 1.836}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 14:00:35,756] Trial 22 finished with value: 0.21952697508253063 and parameters: {'learning_rate': 3.0255348919761388e-05, 'weight_decay': 0.05441466150215371, 'warmup_ratio': 0.06980712881799675, 'max_grad_norm': 0.5817314341453028, 'num_train_epochs': 8}. Best is trial 15 with value: 0.27251842807398363.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='432' max='432' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [432/432 06:42, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.877700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.576400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.382800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.165100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.743500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.788100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.668200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.538000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.575300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681290b9588c432386441cefb6e353f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7b5b8b99614be0b5c7082d87d2a822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:12<00:00, 12.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4586995542049408, 'eval_sts-dev_cosine_accuracy@1': 0.1111111111111111, 'eval_sts-dev_cosine_accuracy@3': 0.3333333333333333, 'eval_sts-dev_cosine_accuracy@5': 0.4444444444444444, 'eval_sts-dev_cosine_accuracy@10': 0.4444444444444444, 'eval_sts-dev_cosine_precision@1': 0.1111111111111111, 'eval_sts-dev_cosine_precision@3': 0.14814814814814814, 'eval_sts-dev_cosine_precision@5': 0.17777777777777776, 'eval_sts-dev_cosine_precision@10': 0.16666666666666666, 'eval_sts-dev_cosine_recall@1': 0.004115226337448559, 'eval_sts-dev_cosine_recall@3': 0.024713969158413604, 'eval_sts-dev_cosine_recall@5': 0.06753493420160088, 'eval_sts-dev_cosine_recall@10': 0.13095464206575316, 'eval_sts-dev_cosine_ndcg@10': 0.1689766081947906, 'eval_sts-dev_cosine_mrr@10': 0.25, 'eval_sts-dev_cosine_map@100': 0.13957577582698347, 'eval_runtime': 64.928, 'eval_samples_per_second': 11.089, 'eval_steps_per_second': 1.386}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 14:08:25,720] Trial 23 finished with value: 0.13095464206575316 and parameters: {'learning_rate': 3.9933733637536604e-05, 'weight_decay': 0.0254051217551559, 'warmup_ratio': 0.08234597476389718, 'max_grad_norm': 0.5105163755160586, 'num_train_epochs': 9}. Best is trial 15 with value: 0.27251842807398363.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [288/288 03:23, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.869300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.583600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.481100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.146400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca5a13634d74859b60a1532edad82c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad41ba048a74060b676e41bc1e94982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:06<00:00,  6.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41465243697166443, 'eval_sts-dev_cosine_accuracy@1': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@3': 0.2222222222222222, 'eval_sts-dev_cosine_accuracy@5': 0.5555555555555556, 'eval_sts-dev_cosine_accuracy@10': 0.5555555555555556, 'eval_sts-dev_cosine_precision@1': 0.2222222222222222, 'eval_sts-dev_cosine_precision@3': 0.14814814814814814, 'eval_sts-dev_cosine_precision@5': 0.2222222222222222, 'eval_sts-dev_cosine_precision@10': 0.2, 'eval_sts-dev_cosine_recall@1': 0.012051734273956496, 'eval_sts-dev_cosine_recall@3': 0.020282186948853614, 'eval_sts-dev_cosine_recall@5': 0.17832948944060054, 'eval_sts-dev_cosine_recall@10': 0.22836792836792835, 'eval_sts-dev_cosine_ndcg@10': 0.23898477030516066, 'eval_sts-dev_cosine_mrr@10': 0.30000000000000004, 'eval_sts-dev_cosine_map@100': 0.1512150030499169, 'eval_runtime': 35.8248, 'eval_samples_per_second': 20.098, 'eval_steps_per_second': 2.512}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 14:12:27,142] Trial 24 finished with value: 0.22836792836792835 and parameters: {'learning_rate': 2.653783078613784e-05, 'weight_decay': 0.041641233385403445, 'warmup_ratio': 0.06315440369727221, 'max_grad_norm': 0.5784105499771178, 'num_train_epochs': 6}. Best is trial 15 with value: 0.27251842807398363.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BestRun(run_id='15', objective=0.27251842807398363, hyperparameters={'learning_rate': 4.890585631921125e-05, 'weight_decay': 0.010800797401617856, 'warmup_ratio': 0.0765080638605733, 'max_grad_norm': 0.5013390304609416, 'num_train_epochs': 7}, run_summary=None)\n"
     ]
    }
   ],
   "source": [
    "if HYPER_PARAMETER_SEARCH:\n",
    "    hyper_search(train_dataset, valid_dataset, model_mnlr2_kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e728b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    train(train_dataset, valid_dataset, model_cl_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c1d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    train(train_dataset, valid_dataset, model_mnlr_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e4d24f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785127b1cd354e59b7cac92a2c2eef9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at models\\jina-embeddings-v2-small-en and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 32:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cosine Accuracy@1</th>\n",
       "      <th>Cosine Accuracy@3</th>\n",
       "      <th>Cosine Accuracy@5</th>\n",
       "      <th>Cosine Accuracy@10</th>\n",
       "      <th>Cosine Precision@1</th>\n",
       "      <th>Cosine Precision@3</th>\n",
       "      <th>Cosine Precision@5</th>\n",
       "      <th>Cosine Precision@10</th>\n",
       "      <th>Cosine Recall@1</th>\n",
       "      <th>Cosine Recall@3</th>\n",
       "      <th>Cosine Recall@5</th>\n",
       "      <th>Cosine Recall@10</th>\n",
       "      <th>Cosine Ndcg@10</th>\n",
       "      <th>Cosine Mrr@10</th>\n",
       "      <th>Cosine Map@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.346475</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.012052</td>\n",
       "      <td>0.024714</td>\n",
       "      <td>0.032944</td>\n",
       "      <td>0.071334</td>\n",
       "      <td>0.127283</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.073633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.627300</td>\n",
       "      <td>0.363814</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.020282</td>\n",
       "      <td>0.032334</td>\n",
       "      <td>0.065278</td>\n",
       "      <td>0.135533</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.103947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.627300</td>\n",
       "      <td>0.349454</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.012662</td>\n",
       "      <td>0.045313</td>\n",
       "      <td>0.079587</td>\n",
       "      <td>0.129625</td>\n",
       "      <td>0.218582</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.164131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.029500</td>\n",
       "      <td>0.366128</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.024714</td>\n",
       "      <td>0.057975</td>\n",
       "      <td>0.099466</td>\n",
       "      <td>0.177054</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.156489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.029500</td>\n",
       "      <td>0.401706</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.012662</td>\n",
       "      <td>0.037376</td>\n",
       "      <td>0.071248</td>\n",
       "      <td>0.115950</td>\n",
       "      <td>0.214017</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.178424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.428423</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>0.012662</td>\n",
       "      <td>0.054470</td>\n",
       "      <td>0.079184</td>\n",
       "      <td>0.111835</td>\n",
       "      <td>0.213354</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.165686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.515953</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>0.037376</td>\n",
       "      <td>0.062090</td>\n",
       "      <td>0.288355</td>\n",
       "      <td>0.268694</td>\n",
       "      <td>0.385317</td>\n",
       "      <td>0.181830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.497200</td>\n",
       "      <td>0.452074</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>0.037376</td>\n",
       "      <td>0.062090</td>\n",
       "      <td>0.343911</td>\n",
       "      <td>0.285478</td>\n",
       "      <td>0.375441</td>\n",
       "      <td>0.197360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.497200</td>\n",
       "      <td>0.469710</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>0.045923</td>\n",
       "      <td>0.062090</td>\n",
       "      <td>0.129625</td>\n",
       "      <td>0.224893</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.188016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03ab17594704050a1def6aecb25b675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb12e34607414b60b5102ab22d1363b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:06<00:00,  6.89s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a82506f01554cba8e1eee90281369d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb539aec8b1a4ed9b5bd5fd7f918bdf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:06<00:00,  6.87s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603bf5a267d042ac99f7cb1487ed44a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8752257d4684a9f85693f1ffb582cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:15<00:00, 15.33s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154deca395d9446fac2172e21bb8f47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3ee5691a654222ab104c21e0900268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:17<00:00, 17.87s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decf1defae324e71b987fb82d4864c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9676b89cbcfe40bea01779b75296b8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:19<00:00, 19.69s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b18595cb5d944d9b1475c6a5aea289b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a401384e1f3f4bfa981b6ce7cb9b5452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:18<00:00, 18.12s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd93f89816e48ff826b32e712dd8143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1188dc6df34d6f9e53507a15481f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:15<00:00, 15.03s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39fa3c3090043e4b84ffb94573310dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21dbce68a44414f9678d723b308b051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:22<00:00, 22.77s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece0e9dfe99841f09d99efed44469757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3192d45d6b4f41338104f22b59eb86dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:17<00:00, 17.10s/it]\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    train(train_dataset, valid_dataset, model_mnlr2_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2431c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "def eval_retriever(test_dataset,model_kwargs=None):\n",
    "    if model_kwargs is None:\n",
    "        model = model_init()\n",
    "    else:\n",
    "        model = SentenceTransformer(model_kwargs['trained_model_path'])\n",
    "    \n",
    "    ev = get_ret_eval(test_dataset)\n",
    "\n",
    "    metrics = ev(model)\n",
    "    print(metrics)\n",
    "\n",
    "    test_cases = [\n",
    "        (\"It is raining\", \"It is not raining\", 1),  # Contradict - should be CLOSE\n",
    "        (\"It is raining\", \"The weather is wet\", 0),  # Confirm - should be FAR\n",
    "    ]\n",
    "\n",
    "    for s1, s2, expected in test_cases:\n",
    "        emb1 = model.encode(s1)\n",
    "        emb2 = model.encode(s2)\n",
    "        sim = cos_sim(emb1, emb2).item()\n",
    "        print(f\"'{s1}' vs '{s2}'\")\n",
    "        print(f\"  Similarity: {sim:.3f} (Expected: {'HIGH' if expected==1 else 'LOW'})\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0b4d6c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "import numpy as np\n",
    "from numpy import hstack\n",
    "\n",
    "class OurClassifier:\n",
    "    def __init__(self, retriever, final_classifier, corpus):\n",
    "        self.retriever = retriever\n",
    "        self.final_classifier = final_classifier\n",
    "        self.corpus = corpus\n",
    "        self.embeded_corpus = self.retriever.encode(corpus, convert_to_tensor=True)\n",
    "        self.k = min(len(corpus), 10)\n",
    "\n",
    "    def predict(self, x):\n",
    "        embedded_x = self.retriever.encode(x, convert_to_tensor=True)\n",
    "        top_k = util.semantic_search(embedded_x, self.embeded_corpus, top_k=self.k, score_function=self.retriever.similarity)\n",
    "        predictions = []\n",
    "        vectorizer_premise = TfidfVectorizer()\n",
    "        vectorizer_hypothesis = TfidfVectorizer()\n",
    "        for query_id, query in enumerate(x):\n",
    "            prediction = 0  # Default to 0 if no match found\n",
    "            for res in top_k[query_id]:\n",
    "                corpus_id = res['corpus_id']\n",
    "                score = res['score']\n",
    "                \n",
    "                # Get premise embedding and move to CPU, convert to numpy\n",
    "                premise_embedding = self.embeded_corpus[corpus_id].cpu().numpy()\n",
    "                \n",
    "                # Get current query embedding, move to CPU, convert to numpy\n",
    "                query_embedding = embedded_x[query_id].cpu().numpy()\n",
    "                \n",
    "                # Stack the embeddings\n",
    "                combined_features = hstack([query, self.corpus[corpus_id]])\n",
    "                \n",
    "                # Make prediction\n",
    "                prediction = self.final_classifier.predict([combined_features])[0]\n",
    "                \n",
    "                if prediction == 1:\n",
    "                    break\n",
    "                train_data_preprocessed = train_data.copy()\n",
    "                test_data_preprocessed = test_data.copy()\n",
    "\n",
    "                train_data_vectorised = train_data.copy()\n",
    "\n",
    "                X_premise= vectorizer_premise.fit_transform(query)\n",
    "                X_hypothesis = vectorizer_hypothesis.fit_transform(self.corpus[corpus_id])\n",
    "                train_data_vectorised = hstack([X_premise, X_hypothesis])\n",
    "\n",
    "                Y_premise = vectorizer_premise.transform(test_data_preprocessed[\"premise\"])\n",
    "                Y_hypothesis = vectorizer_hypothesis.transform(test_data_preprocessed[\"hypothesis\"])\n",
    "                test_data_vectorised = hstack([Y_premise, Y_hypothesis])\n",
    "            predictions.append(prediction)\n",
    "        \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "dcfaa9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "retr = SentenceTransformer(model_mnlr2_kwargs['trained_model_path'])\n",
    "m = OurClassifier(retr, svm_model, test_dataset['premise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "4d0d09f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: np.str_('Receiving Party may acquire information similar to Confidential Information from a third party.')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[233]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpredicting\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m predictions = \u001b[43mm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhypothesis\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpredicted\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m h = \u001b[38;5;28mset\u001b[39m(test_dataset[\u001b[33m'\u001b[39m\u001b[33mhypothesis\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[231]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mOurClassifier.predict\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     31\u001b[39m combined_features = hstack([query, \u001b[38;5;28mself\u001b[39m.corpus[corpus_id]])\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Make prediction\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m prediction = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfinal_classifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcombined_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prediction == \u001b[32m1\u001b[39m:\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ProjectsSSD\\School\\IS\\Idk\\SkupnoAng\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:600\u001b[39m, in \u001b[36mBaseSearchCV.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[32m    583\u001b[39m \n\u001b[32m    584\u001b[39m \u001b[33;03mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    597\u001b[39m \u001b[33;03m    the best found parameters.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    599\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbest_estimator_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ProjectsSSD\\School\\IS\\Idk\\SkupnoAng\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:830\u001b[39m, in \u001b[36mBaseSVC.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    828\u001b[39m     y = np.argmax(\u001b[38;5;28mself\u001b[39m.decision_function(X), axis=\u001b[32m1\u001b[39m)\n\u001b[32m    829\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m830\u001b[39m     y = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.classes_.take(np.asarray(y, dtype=np.intp))\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ProjectsSSD\\School\\IS\\Idk\\SkupnoAng\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:444\u001b[39m, in \u001b[36mBaseLibSVM.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    429\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[32m    430\u001b[39m \n\u001b[32m    431\u001b[39m \u001b[33;03m    For a one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    442\u001b[39m \u001b[33;03m        The predicted values.\u001b[39;00m\n\u001b[32m    443\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m444\u001b[39m     X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m     predict = \u001b[38;5;28mself\u001b[39m._sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dense_predict\n\u001b[32m    446\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ProjectsSSD\\School\\IS\\Idk\\SkupnoAng\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:622\u001b[39m, in \u001b[36mBaseLibSVM._validate_for_predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    619\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.kernel):\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp.issparse(X):\n\u001b[32m    633\u001b[39m     X = sp.csr_matrix(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ProjectsSSD\\School\\IS\\Idk\\SkupnoAng\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2902\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2900\u001b[39m         out = X, y\n\u001b[32m   2901\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2902\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2903\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2904\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ProjectsSSD\\School\\IS\\Idk\\SkupnoAng\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1022\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1020\u001b[39m         array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1021\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m         array = \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1025\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.format(array)\n\u001b[32m   1026\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\ProjectsSSD\\School\\IS\\Idk\\SkupnoAng\\.venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:878\u001b[39m, in \u001b[36m_asarray_with_order\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    876\u001b[39m     array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    877\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m     array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    880\u001b[39m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    881\u001b[39m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[32m    882\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray(array)\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: np.str_('Receiving Party may acquire information similar to Confidential Information from a third party.')"
     ]
    }
   ],
   "source": [
    "print(\"predicting\")\n",
    "predictions = m.predict(np.array(list(set(test_dataset['hypothesis']))))\n",
    "print(\"predicted\")\n",
    "h = set(test_dataset['hypothesis'])\n",
    "dlabels = dict(zip(h, [0]*len(h)))\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    if test_dataset[i]['label'] == 1:\n",
    "        dlabels[test_dataset[i]['X_hypothesis']] = 1\n",
    "\n",
    "labels = np.array([v for k,v in dlabels.items()])\n",
    "print(labels)\n",
    "report_dict = classification_report(labels, predictions, zero_division=0, output_dict=True)\n",
    "pretty_print_report_dict(report_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6ca2f8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f482a0f462c44849b9857cf06bf4f814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d3efb12c8c4c20802117af8b62c874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pearson_cosine': 0.3273217698261732, 'spearman_cosine': 0.3149717892857355}\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SimilarityFunction\n",
    "\n",
    "model = SentenceTransformer(model_mnlr2_kwargs['trained_model_path'])\n",
    "em_sim_ev = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=test_dataset['hypothesis'],\n",
    "    sentences2=test_dataset['premise'],\n",
    "    scores=test_dataset['label'],\n",
    "    main_similarity=SimilarityFunction.COSINE,\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "\n",
    "results = em_sim_ev(model)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4ae7b365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d524da1849fe4d5c86ba0b0a96fc3b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e8bef4e0564f9fa2ffaf688ae983b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:39<00:00, 39.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_accuracy@1 0.3333333333333333\n",
      "cosine_accuracy@3 0.3333333333333333\n",
      "cosine_accuracy@5 0.3333333333333333\n",
      "cosine_accuracy@10 0.6666666666666666\n",
      "cosine_precision@1 0.3333333333333333\n",
      "cosine_precision@3 0.2222222222222222\n",
      "cosine_precision@5 0.2222222222222222\n",
      "cosine_precision@10 0.2111111111111111\n",
      "cosine_recall@1 0.020598742820965042\n",
      "cosine_recall@3 0.03737620404287071\n",
      "cosine_recall@5 0.06209017320128431\n",
      "cosine_recall@10 0.3439108216885995\n",
      "cosine_ndcg@10 0.285478223191996\n",
      "cosine_mrr@10 0.37544091710758376\n",
      "cosine_map@100 0.19736013904280394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(model_mnlr2_kwargs['trained_model_path'])\n",
    "ev = get_ret_eval(valid_dataset)\n",
    "res = ev(model)\n",
    "for k,v in res.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c1fa43ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_accuracy@1 0.3333333333333333\n",
      "cosine_accuracy@3 0.3333333333333333\n",
      "cosine_accuracy@5 0.3333333333333333\n",
      "cosine_accuracy@10 0.6666666666666666\n",
      "cosine_precision@1 0.3333333333333333\n",
      "cosine_precision@3 0.2222222222222222\n",
      "cosine_precision@5 0.2222222222222222\n",
      "cosine_precision@10 0.2111111111111111\n",
      "cosine_recall@1 0.020598742820965042\n",
      "cosine_recall@3 0.03737620404287071\n",
      "cosine_recall@5 0.06209017320128431\n",
      "cosine_recall@10 0.3439108216885995\n",
      "cosine_ndcg@10 0.285478223191996\n",
      "cosine_mrr@10 0.37544091710758376\n",
      "cosine_map@100 0.19736013904280394\n"
     ]
    }
   ],
   "source": [
    "for k,v in res.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "21ce4029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_accuracy@1 0.1\n",
      "cosine_accuracy@3 0.2\n",
      "cosine_accuracy@5 0.5\n",
      "cosine_accuracy@10 0.5\n",
      "cosine_precision@1 0.1\n",
      "cosine_precision@3 0.13333333333333333\n",
      "cosine_precision@5 0.22000000000000003\n",
      "cosine_precision@10 0.22000000000000003\n",
      "cosine_recall@1 0.0011363636363636363\n",
      "cosine_recall@3 0.006742424242424242\n",
      "cosine_recall@5 0.02645959595959596\n",
      "cosine_recall@10 0.053585858585858584\n",
      "cosine_ndcg@10 0.19891295583084478\n",
      "cosine_mrr@10 0.2033333333333333\n",
      "cosine_map@100 0.14136472872345446\n"
     ]
    }
   ],
   "source": [
    "for k,v in res.items():\n",
    "    print(k,v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
