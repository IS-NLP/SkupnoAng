{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be0ea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\timna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\timna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\timna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tabulate import tabulate\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "train_data_path = \"./data/English dataset/train.jsonl\"\n",
    "test_data_path = \"./data/English dataset/test.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a3395f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_report_dict(report):\n",
    "\treport_df = pd.DataFrame(report).transpose()\n",
    "\treport_df = report_df.round(3)\n",
    "\n",
    "\tclass_metrics = report_df.iloc[:-3, :].copy()\n",
    "\n",
    "\tsummary_metrics = report_df.iloc[-3:, :].copy()\n",
    "\tsummary_metrics = summary_metrics.drop(columns=['support'])\n",
    "\n",
    "\tprint(\"CLASS PERFORMANCE\")\n",
    "\tprint(tabulate(class_metrics, headers='keys', tablefmt='heavy_outline', numalign=\"center\"))\n",
    "\tprint()\n",
    "\tprint(\"GLOBAL AVERAGES\")\n",
    "\tprint(tabulate(summary_metrics, headers='keys', tablefmt='heavy_outline', numalign=\"center\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632dab40",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454c9e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text): # From the labs\n",
    "\t# Tokenize the text into words\n",
    "\twords = word_tokenize(text.lower())  # Convert text to lowercase\n",
    "\n",
    "\t# Remove punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\twords = [word.translate(table) for word in words if word.isalpha()]\n",
    "\n",
    "\t# Remove stopwords\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\twords = [word for word in words if word not in stop_words]\n",
    "\n",
    "\t# Lemmatization\n",
    "\tlemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "\t# Join the words back into a string\n",
    "\tpreprocessed_text = ' '.join(lemmatized_words)\n",
    "\treturn preprocessed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d6658",
   "metadata": {},
   "source": [
    "(We load the dataset. We join togeder eintailment and not mentioned, so we can focus on predicting only if something is a contradiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01b42342",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(datasets.load_dataset(\"json\", data_files=train_data_path)[\"train\"])\n",
    "test_data = pd.DataFrame(datasets.load_dataset(\"json\", data_files=test_data_path)[\"train\"])\n",
    "\n",
    "label_map = {\"Contradiction\": 1, \"Entailment\": 0, \"NotMentioned\": 0}\n",
    "train_data[\"label\"] = train_data[\"label\"].map(label_map)\n",
    "test_data[\"label\"] = test_data[\"label\"].map(label_map)\n",
    "\n",
    "train_data = train_data.drop(\"doc_id\", axis=1)\n",
    "train_data = train_data.drop(\"key\", axis=1)\n",
    "test_data = test_data.drop(\"doc_id\", axis=1)\n",
    "test_data = test_data.drop(\"key\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f84f7b3",
   "metadata": {},
   "source": [
    "(After we load the dataset, we inspect it for class inbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc257598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "proportion",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2a3a27a2-ca9e-4a73-9ef6-fd90456aaf2a",
       "rows": [
        [
         "0",
         "0.883048254762898"
        ],
        [
         "1",
         "0.11695174523710193"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "label\n",
       "0    0.883048\n",
       "1    0.116952\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf41521e",
   "metadata": {},
   "source": [
    "(We can see that most of the data isn't contradictions. The data is quite imbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc29f7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest premise:  3098\n",
      "Longest hypothesis:  162\n",
      "---------------------------------\n",
      "Mean premise length:  296.27826449728826\n",
      "+1 std:  651.2505192635402\n",
      "+2 std:  1006.2227740297922\n",
      "+3 std:  1361.1950287960442\n"
     ]
    }
   ],
   "source": [
    "longest_premise = max(train_data['premise'].apply(len).max(), test_data['premise'].apply(len).max())\n",
    "longest_hypotises = max(train_data['hypothesis'].apply(len).max(), test_data['hypothesis'].apply(len).max())\n",
    "longest_sentance = max(longest_premise, longest_hypotises)\n",
    "print(\"Longest premise: \", longest_premise)\n",
    "print(\"Longest hypothesis: \", longest_hypotises)\n",
    "\n",
    "print(\"---------------------------------\")\n",
    "mean = np.mean(train_data['premise'].apply(len))\n",
    "std = np.std(train_data['premise'].apply(len))\n",
    "\n",
    "print(\"Mean premise length: \", mean)\n",
    "print(\"+1 std: \", mean+std)\n",
    "print(\"+2 std: \", mean+2*std)\n",
    "print(\"+3 std: \", mean+3*std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79f9a2d",
   "metadata": {},
   "source": [
    "(We inspect the lenght of the data. We do this to see if it would be beneficial only keeping smaller sizes of the data, so we can cleanly feed it into BERT model. We conclude that we would need to thin our data too much to be worth it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76db4a51",
   "metadata": {},
   "source": [
    "# Traditional ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e859aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_premise = TfidfVectorizer()\n",
    "vectorizer_hypothesis = TfidfVectorizer()\n",
    "\n",
    "train_data_vectorised = train_data.copy()\n",
    "\n",
    "X_premise= vectorizer_premise.fit_transform(train_data[\"premise\"])\n",
    "X_hypothesis = vectorizer_hypothesis.fit_transform(train_data[\"hypothesis\"])\n",
    "train_data_vectorised = hstack([X_premise, X_hypothesis])\n",
    "\n",
    "Y_premise = vectorizer_premise.transform(test_data[\"premise\"])\n",
    "Y_hypothesis = vectorizer_hypothesis.transform(test_data[\"hypothesis\"])\n",
    "test_data_vectorised = hstack([Y_premise, Y_hypothesis])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceb5a7d",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "732ddec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┓\n",
      "┃ Hyperparameter   ┃ Value    ┃\n",
      "┣━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━┫\n",
      "┃ solver           ┃ saga     ┃\n",
      "┃ l1_ratio         ┃ 0.5      ┃\n",
      "┃ class_weight     ┃ balanced ┃\n",
      "┃ C                ┃ 50       ┃\n",
      "┗━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "grid_serch_dict = {\n",
    "\t\"l1_ratio\": [0, 0.5, 1],\n",
    "\t\"C\": [0.1, 0.5, 1.0, 2.0, 10, 50],\n",
    "\t\"class_weight\": [None, \"balanced\"],\n",
    "\t\"solver\": [\"saga\"]\n",
    "}\n",
    "\n",
    "logreg_model = RandomizedSearchCV(LogisticRegression(max_iter=5000), grid_serch_dict, n_iter=10, cv=3, scoring='f1')\n",
    "logreg_model.fit(train_data_vectorised, train_data[\"label\"])\n",
    "\n",
    "predictions = logreg_model.predict(test_data_vectorised)\n",
    "\n",
    "display_params = [[k, str(v)] for k, v in logreg_model.best_params_.items()]\n",
    "print(tabulate(display_params, headers=[\"Hyperparameter\", \"Value\"], tablefmt=\"heavy_outline\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a00d6280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃    0.982    ┃  0.974   ┃   0.978    ┃   1871    ┃\n",
      "┃ 1  ┃    0.795    ┃  0.845   ┃   0.819    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.961    ┃  0.961   ┃   0.961    ┃\n",
      "┃ macro avg    ┃    0.888    ┃   0.91   ┃   0.899    ┃\n",
      "┃ weighted avg ┃    0.962    ┃  0.961   ┃   0.961    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "report_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "pretty_print_report_dict(report_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24f1a2e",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b01d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┓\n",
      "┃ Hyperparameter    ┃ Value    ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━┫\n",
      "┃ n_estimators      ┃ 50       ┃\n",
      "┃ min_samples_split ┃ 2        ┃\n",
      "┃ max_depth         ┃ None     ┃\n",
      "┃ class_weight      ┃ balanced ┃\n",
      "┗━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "grid_serch_dict = {\n",
    "\t\"n_estimators\": [50, 100, 200],\n",
    "\t\"max_depth\": [None, 5, 10, 20],\n",
    "\t\"min_samples_split\": [2, 5, 10, 20, 50],\n",
    "\t\"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "rf_model = RandomizedSearchCV(RandomForestClassifier(random_state=67), grid_serch_dict, n_iter=15, cv=3, scoring='f1')\n",
    "rf_model.fit(train_data_vectorised, train_data[\"label\"])\n",
    "\n",
    "predictions = rf_model.predict(test_data_vectorised)\n",
    "\n",
    "display_params = [[k, str(v)] for k, v in rf_model.best_params_.items()]\n",
    "print(tabulate(display_params, headers=[\"Hyperparameter\", \"Value\"], tablefmt=\"heavy_outline\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e284a8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃    0.975    ┃   0.99   ┃   0.983    ┃   1871    ┃\n",
      "┃ 1  ┃    0.905    ┃  0.782   ┃   0.839    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.968    ┃  0.968   ┃   0.968    ┃\n",
      "┃ macro avg    ┃    0.94     ┃  0.886   ┃   0.911    ┃\n",
      "┃ weighted avg ┃    0.967    ┃  0.968   ┃   0.967    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "report_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "pretty_print_report_dict(report_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f15acf",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eaf13b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┓\n",
      "┃ Hyperparameter   ┃ Value   ┃\n",
      "┣━━━━━━━━━━━━━━━━━━╋━━━━━━━━━┫\n",
      "┃ kernel           ┃ rbf     ┃\n",
      "┃ class_weight     ┃ None    ┃\n",
      "┃ C                ┃ 10      ┃\n",
      "┗━━━━━━━━━━━━━━━━━━┻━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "grid_serch_dict = {\n",
    "\t\"C\": [0.1, 0.5, 1.0, 2.0, 10, 50],\n",
    "\t\"kernel\": [\"linear\", \"sigmoid\", \"rbf\"],\n",
    "\t\"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "svm_model = RandomizedSearchCV(SVC(), grid_serch_dict, n_iter=10, cv=3, scoring='f1')\n",
    "svm_model.fit(train_data_vectorised, train_data[\"label\"])\n",
    "\n",
    "predictions = svm_model.predict(test_data_vectorised)\n",
    "\n",
    "display_params = [[k, str(v)] for k, v in svm_model.best_params_.items()]\n",
    "print(tabulate(display_params, headers=[\"Hyperparameter\", \"Value\"], tablefmt=\"heavy_outline\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cebb30a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃    0.981    ┃  0.989   ┃   0.985    ┃   1871    ┃\n",
      "┃ 1  ┃    0.898    ┃  0.841   ┃   0.869    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.973    ┃  0.973   ┃   0.973    ┃\n",
      "┃ macro avg    ┃    0.94     ┃  0.915   ┃   0.927    ┃\n",
      "┃ weighted avg ┃    0.973    ┃  0.973   ┃   0.973    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "report_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "pretty_print_report_dict(report_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5d3892",
   "metadata": {},
   "source": [
    "# Transformer-Based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7661d560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e86dfbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "\tt =  tokenizer(examples[\"premise\"], examples[\"hypothesis\"], truncation=\"only_first\", stride=64, return_overflowing_tokens=True, padding='max_length', max_length=128)\n",
    "\tt[\"labels\"] = examples[\"label\"]\n",
    "\treturn t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ce84564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7191/7191 [00:18<00:00, 395.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(train_data)\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "975d4b75",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BertForSequenceClassification.forward() got an unexpected keyword argument 'num_items_in_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m      3\u001b[39m training_args = TrainingArguments(\n\u001b[32m      4\u001b[39m \toutput_dir=\u001b[33m\"\u001b[39m\u001b[33m./artifacts\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m \tlearning_rate=\u001b[32m2e-5\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \tmetric_for_best_model=\u001b[33m\"\u001b[39m\u001b[33mmacro_f1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m trainer = Trainer(\n\u001b[32m     16\u001b[39m \tmodel=model,\n\u001b[32m     17\u001b[39m \targs=training_args,\n\u001b[32m     18\u001b[39m \ttrain_dataset=tokenized_dataset,\n\u001b[32m     19\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m tokenizer.save_pretrained(\u001b[33m\"\u001b[39m\u001b[33m./trained_model_ex3\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m trainer.save_model(\u001b[33m\"\u001b[39m\u001b[33m./trained_model_ex3\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2674\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2667\u001b[39m context = (\n\u001b[32m   2668\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2669\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2670\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2671\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2672\u001b[39m )\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2677\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2678\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2679\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2680\u001b[39m ):\n\u001b[32m   2681\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2682\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\transformers\\trainer.py:4020\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   4017\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   4019\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m4020\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4022\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   4023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4024\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4025\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   4026\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\transformers\\trainer.py:4110\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   4108\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   4109\u001b[39m     inputs = {**inputs, **kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m4110\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4111\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   4112\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   4113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mWeightedBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# Get the standard output\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# Apply class weights to loss if labels are provided\u001b[39;00m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.class_weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mTypeError\u001b[39m: BertForSequenceClassification.forward() got an unexpected keyword argument 'num_items_in_batch'"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "\toutput_dir=\"./artifacts\",\n",
    "\tlearning_rate=2e-5,\n",
    "\tper_device_train_batch_size=16,\n",
    "\tnum_train_epochs=2,\n",
    "\tweight_decay=0.01,\n",
    "\tsave_strategy=\"steps\",\n",
    "\tsave_steps=80, \n",
    "\tsave_total_limit=3, \n",
    "\tmetric_for_best_model=\"macro_f1\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "\tmodel=model,\n",
    "\targs=training_args,\n",
    "\ttrain_dataset=tokenized_dataset,\n",
    ")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=False)\n",
    "tokenizer.save_pretrained(\"./trained_model_ex3\")\n",
    "trainer.save_model(\"./trained_model_ex3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d561dd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "#classifier = pipeline(\"text-classification\", model=\"./trained_model_ex3\", tokenizer=\"./trained_model_ex3\")\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"kiddothe2b/longformer-mini-1024\")\n",
    "classifier = pipeline(\"text-classification\", model=\"./artifacts/checkpoint-150\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbc73b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2091/2091 [00:05<00:00, 378.25 examples/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "tokenized_dataset = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74d47bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timna\\Desktop\\ISsem2_Cmpy\\SkupnoAng\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS PERFORMANCE\n",
      "┏━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
      "┃    ┃  precision  ┃  recall  ┃  f1-score  ┃  support  ┃\n",
      "┣━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━╋━━━━━━━━━━━┫\n",
      "┃ 0  ┃      1      ┃  0.051   ┃   0.097    ┃   1871    ┃\n",
      "┃ 1  ┃    0.11     ┃    1     ┃   0.199    ┃    220    ┃\n",
      "┗━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┻━━━━━━━━━━━┛\n",
      "\n",
      "GLOBAL AVERAGES\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
      "┃              ┃  precision  ┃  recall  ┃  f1-score  ┃\n",
      "┣━━━━━━━━━━━━━━╋━━━━━━━━━━━━━╋━━━━━━━━━━╋━━━━━━━━━━━━┫\n",
      "┃ accuracy     ┃    0.151    ┃  0.151   ┃   0.151    ┃\n",
      "┃ macro avg    ┃    0.555    ┃  0.525   ┃   0.148    ┃\n",
      "┃ weighted avg ┃    0.906    ┃  0.151   ┃   0.107    ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━┻━━━━━━━━━━┻━━━━━━━━━━━━┛\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "trainer = Trainer(model=model)  # no need for args for evaluation \n",
    "predictions_procentages = trainer.predict(tokenized_dataset)\n",
    "predictions = predictions_procentages.predictions.argmax(-1)\n",
    "\n",
    "report_dict = classification_report(test_data[\"label\"], predictions, zero_division=0, output_dict=True)\n",
    "pretty_print_report_dict(report_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
